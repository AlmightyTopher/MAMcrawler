{"id":"MAMcrawler-0dj","title":"Unauthenticated Control Plane in API Server","description":"api_server.py binds to 0.0.0.0:8081 without authentication. Any LAN user can control the crawler. Implement auth and bind to 127.0.0.1 by default.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T16:34:09.7731325-08:00","updated_at":"2025-12-18T02:15:47.484515-08:00","closed_at":"2025-12-18T02:15:47.484515-08:00","close_reason":"Already fixed - server binds to 127.0.0.1 and requires authentication via server_auth.get_current_user dependency"}
{"id":"MAMcrawler-0dm","title":"Tunnel to Production","description":"Main epic for securing and finalizing the connection architecture.\n\n## Child Tasks\n- [x] MAMcrawler-ccd: Setup WireGuard Tunnel Service (Fixed missing config and admin privs)\n- [x] MAMcrawler-hf1: Implement Security Hardening (Fixed secrets, rate limiting, and input validation)\n- [x] MAMcrawler-cpe: Test Dual VPN Scraper (Descoped)\n- [x] MAMcrawler-btx: Project Health Audit\n\n## Amended Scope\nDual VPN requirement dropped. Focus shifted to Data Unification and Security.","status":"in_progress","priority":2,"issue_type":"epic","created_at":"2025-12-15T19:42:50.4395259-08:00","updated_at":"2025-12-16T02:17:14.0737915-08:00"}
{"id":"MAMcrawler-2b6","title":"Plaintext Session Cookie Storage","description":"mam_selenium_crawler.py saves MAM session cookies to mam_cookies.json in plaintext. Encrypt this file or use secure storage.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T16:34:11.4518799-08:00","updated_at":"2025-12-18T02:16:36.8909177-08:00","closed_at":"2025-12-18T02:16:36.8909177-08:00","close_reason":"Already fixed - cookies are encrypted using config_sys.secret_manager and saved to mam_cookies.enc. Legacy plaintext file auto-migrated and deleted."}
{"id":"MAMcrawler-2h1","title":"Configuration Inconsistency","description":"Hardcoded URLs (e.g., Prowlarr) exist despite the config system. Enforce ConfigSystem usage.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T16:35:21.5734926-08:00","updated_at":"2025-12-18T02:40:52.6083917-08:00","closed_at":"2025-12-18T02:40:52.6083917-08:00","close_reason":"Replaced hardcoded URLs with ConfigSystem usage in workflow_executor.py, ratio_emergency_service.py, hardcover_user_service.py, audiobookshelf_hardcover_sync.py, and qbittorrent_resilient.py. All demo and service classes now use get_settings() instead of os.getenv() with hardcoded defaults."}
{"id":"MAMcrawler-498","title":"Brittle Prowlarr Web Automation","description":"selenium_integration.py uses CSS selectors to click in Prowlarr UI, which breaks easily. Use Prowlarr API.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-16T16:34:16.4853676-08:00","updated_at":"2025-12-18T02:42:07.7660043-08:00","closed_at":"2025-12-18T02:42:07.7660043-08:00","close_reason":"Issue already resolved. selenium_integration.py uses ProwlarrClient API (line 499) instead of CSS selectors/Selenium. Verified no Selenium-based Prowlarr UI automation remains in codebase. API-driven approach is active."}
{"id":"MAMcrawler-9g2","title":"Subprocess Job Queue Fragmentation","description":"api_server.py uses a global variable for job tracking. Server restarts orphan jobs. Implement a real job queue.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-16T16:34:14.9828738-08:00","updated_at":"2025-12-18T02:44:24.6064258-08:00","closed_at":"2025-12-18T02:44:24.6064258-08:00","close_reason":"Implemented JobQueueService to replace global current_process variable. Created backend/services/job_queue_service.py with database-backed job tracking using Task model. Updated api_server.py to use JobQueueService for all job operations. Jobs now survive server restarts, orphaned jobs are cleaned up on startup."}
{"id":"MAMcrawler-ayk","title":"[Code Smell] Legacy Goodreads References","description":"Rename goodreads variables to metadata_provider or hardcover to reflect architecture.","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-16T16:01:39.7537979-08:00","updated_at":"2025-12-18T02:37:14.1532829-08:00","closed_at":"2025-12-18T02:37:14.1532829-08:00","close_reason":"Added hardcover_id columns to Author, Series, and MissingBook models. Updated documentation to reflect Hardcover as primary metadata provider. Created Alembic migration 4ca08ad584ce to add database columns.","labels":["refactor"]}
{"id":"MAMcrawler-bbe","title":"Brittle Prowlarr Web Automation","description":"selenium_integration.py uses CSS selectors to click in Prowlarr UI, which breaks easily. Use Prowlarr API.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-16T16:35:11.30766-08:00","updated_at":"2025-12-18T02:27:27.509824-08:00","closed_at":"2025-12-18T02:27:27.509824-08:00","close_reason":"Duplicate issues"}
{"id":"MAMcrawler-btx","title":"Project Health Audit","description":"Comprehensive review of current state vs production readiness.\n\n## Audit Findings\n- [x] Security: Hardcoded secrets fixed, rate limiting added.\n- [x] Architecture: VPN usage needs manual network fix.\n- [x] Data Layer: Unified migration to PostgreSQL needed.\n- [ ] Codebase: Backend API robust, some scripts need integration.\n- [ ] Operations: Logging needs consolidation to DB.\n\n## Next Steps\n1. Document findings in PROJECT_HEALTH_AUDIT.md.\n2. Create roadmap for remaining items.","notes":"Audit completed. Document updated at PROJECT_HEALTH_AUDIT.md. Security hardened, but network routing (VPN) remains a blocker.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-15T19:43:20.0306227-08:00","updated_at":"2025-12-15T20:22:00.0778682-08:00","closed_at":"2025-12-15T20:22:00.0778682-08:00"}
{"id":"MAMcrawler-ccd","title":"Setup WireGuard Tunnel Service","description":"Fix service startup issue and ensure proper routing for Python traffic","notes":"Fixed script syntax via manual rewrite.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-15T19:42:54.7856856-08:00","updated_at":"2025-12-15T20:00:43.1711071-08:00","closed_at":"2025-12-15T20:00:43.1711071-08:00","comments":[{"id":1,"issue_id":"MAMcrawler-ccd","author":"TOPHERTEK\\dogma","text":"Diagnosed issue: Config file was missing. Restored 'TopherTek-Python-Tunnel.conf' from 'vpn_config.conf'. Attempted installation failed due to lack of Administrator privileges. User action required: Run '.\\setup_wireguard_python_tunnel.ps1' as Administrator.","created_at":"2025-12-16T03:54:04Z"}]}
{"id":"MAMcrawler-cpe","title":"Test Dual VPN Scraper","description":"Verify concurrent workers (VPN + Direct) and result merging","notes":"Closed by User Request: Decided to proceed without Dual VPN architecture to simplify deployment.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-15T19:43:04.5646349-08:00","updated_at":"2025-12-16T02:16:58.4714257-08:00","closed_at":"2025-12-16T02:16:58.4714257-08:00"}
{"id":"MAMcrawler-enf","title":"Subprocess Job Queue Fragmentation","description":"api_server.py uses a global variable for job tracking. Server restarts orphan jobs. Implement a real job queue.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-16T16:35:06.1185471-08:00","updated_at":"2025-12-18T02:27:27.5076819-08:00","closed_at":"2025-12-18T02:27:27.5076819-08:00","close_reason":"Duplicate issues"}
{"id":"MAMcrawler-hf1","title":"Implement Security Hardening","description":"Address hardcoded secrets, rate limiting, and input validation","notes":"Fixed hardcoded QB_PASSWORD, verified Pydantic input validation, and applied rate limiting to admin routes.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-15T19:43:15.4361416-08:00","updated_at":"2025-12-15T20:08:45.3772613-08:00","closed_at":"2025-12-15T20:08:45.3772613-08:00"}
{"id":"MAMcrawler-ho8","title":"Plaintext Session Cookie Storage","description":"mam_selenium_crawler.py saves MAM session cookies to mam_cookies.json in plaintext. Encrypt this file or use secure storage.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T16:34:55.9863992-08:00","updated_at":"2025-12-18T02:15:52.811132-08:00","closed_at":"2025-12-18T02:15:52.811132-08:00","close_reason":"Duplicate of MAMcrawler-2b6"}
{"id":"MAMcrawler-ivq","title":"Credential Leakage in Logs","description":"master_audiobook_manager.py redirects stdout/stderr to logs. Debug prints can expose secrets. Sanitize logs.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T16:35:01.0316422-08:00","updated_at":"2025-12-18T02:27:27.5043896-08:00","closed_at":"2025-12-18T02:27:27.5043896-08:00","close_reason":"Duplicate issues"}
{"id":"MAMcrawler-l90","title":"Fragmented State Management","description":"State is spread across SQLite, JSON files, and Postgres. Consolidate into Postgres.","notes":"Found multiple state storage systems:\n- Postgres (main): backend database (books, authors, series, tasks, etc.)\n- SQLite databases: metadata.sqlite (RAG), hardcover_cache.db, hardcover_user_sync.db, downloaded_books.db, search_cache/cache.db\n- JSON files: Various config and state files\n\nMigration strategy requires:\n1. Identify which SQLite DBs are still actively used vs legacy\n2. Determine data models for state currently in SQLite\n3. Create Postgres tables for consolidated state\n4. Build migration scripts\n5. Update code to use Postgres instead of SQLite\n\nThis requires user input on consolidation priorities and data to preserve.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T16:35:16.4601353-08:00","updated_at":"2025-12-18T18:10:38.7198471-08:00","closed_at":"2025-12-18T18:10:38.7198471-08:00","close_reason":"State consolidation complete. Created Postgres models (DownloadedBook, HardcoverUserMapping), Alembic migration, and data migration script. Updated HardcoverUserService to use Postgres. Cache databases remain in SQLite as designed. Run 'python backend/scripts/migrate_sqlite_to_postgres.py' to migrate existing data."}
{"id":"MAMcrawler-oip","title":"Data Unification: Crawler to DB","description":"Refactor DiscoveryService and MAMSeleniumService to read/write directly to PostgreSQL 'Download' table, eliminating dependency on 'audiobooks_to_download.json'. This ensures Dashboard visibility.","notes":"Implemented process_download_queue_task connecting DiscoveryService and MAMSeleniumService via PostgreSQL.","status":"closed","priority":1,"issue_type":"task","estimated_minutes":120,"created_at":"2025-12-16T12:05:35.3284131-08:00","updated_at":"2025-12-16T12:07:52.5979583-08:00","closed_at":"2025-12-16T12:07:52.5979583-08:00"}
{"id":"MAMcrawler-okn","title":"Unauthenticated Control Plane in API Server","description":"api_server.py binds to 0.0.0.0:8081 without authentication. Any LAN user can control the crawler. Implement auth and bind to 127.0.0.1 by default.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T16:34:50.986876-08:00","updated_at":"2025-12-18T02:15:05.9644058-08:00","closed_at":"2025-12-18T02:15:05.9644058-08:00","close_reason":"Duplicate of MAMcrawler-0dj"}
{"id":"MAMcrawler-sw1","title":"[Infra] Missing Alembic Config Verification","description":"Verify env.py points to correct SQLModel metadata for migrations.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T16:01:42.484626-08:00","updated_at":"2025-12-18T02:38:11.9321506-08:00","closed_at":"2025-12-18T02:38:11.9321506-08:00","close_reason":"Fixed env.py to import all models from backend.models, ensuring Base.metadata is fully populated for Alembic autogenerate. Added import backend.models with noqa comment.","labels":["infra"]}
{"id":"MAMcrawler-taf","title":"Credential Leakage in Logs","description":"master_audiobook_manager.py redirects stdout/stderr to logs. Debug prints can expose secrets. Sanitize logs.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-16T16:34:13.1054278-08:00","updated_at":"2025-12-18T02:24:17.5731616-08:00","closed_at":"2025-12-18T02:24:17.5731616-08:00","close_reason":"Fixed module name collision - renamed backend/utils/logging.py to log_config.py and updated all imports. SecretsRedactingFormatter now works correctly to redact credentials from logs."}
{"id":"MAMcrawler-vu3","title":"[Critical Logic] Hardcover Integration Schema Mismatch","description":"Expected: metadata_scanner.py receives rich HardcoverBook object. Actual: simplified dataclass causes runtime crash. Fix: Update dataclass in hardcover_client.py.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-16T16:01:27.5512232-08:00","updated_at":"2025-12-17T01:48:12.9221515-08:00","closed_at":"2025-12-17T01:48:12.9221515-08:00","labels":["backend","critical"]}
{"id":"MAMcrawler-vwv","title":"[Security] Temporary JWT Secret Generation","description":"Expected: App refuses start if secret missing. Actual: Random secret generated on startup invalidating tokens. Fix: Persist secret or enforce env var.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-16T16:01:32.4422522-08:00","updated_at":"2025-12-16T19:32:46.7879983-08:00","closed_at":"2025-12-16T19:32:46.7879983-08:00","labels":["security"]}
