Directory structure:
â””â”€â”€ doriandarko-claude-engineer/
    â”œâ”€â”€ readme.md
    â”œâ”€â”€ app.py
    â”œâ”€â”€ ce3.py
    â”œâ”€â”€ config.py
    â”œâ”€â”€ pyproject.toml
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ test.py
    â”œâ”€â”€ .env.example
    â”œâ”€â”€ Claude-Eng-v2/
    â”‚   â”œâ”€â”€ readme.md
    â”‚   â”œâ”€â”€ ollama-eng.py
    â”‚   â””â”€â”€ requirements.txt
    â”œâ”€â”€ prompts/
    â”‚   â””â”€â”€ system_prompts.py
    â”œâ”€â”€ static/
    â”‚   â”œâ”€â”€ css/
    â”‚   â”‚   â””â”€â”€ style.css
    â”‚   â””â”€â”€ js/
    â”‚       â””â”€â”€ chat.js
    â”œâ”€â”€ templates/
    â”‚   â””â”€â”€ index.html
    â””â”€â”€ tools/
        â”œâ”€â”€ base.py
        â”œâ”€â”€ browsertool.py
        â”œâ”€â”€ createfolderstool.py
        â”œâ”€â”€ diffeditortool.py
        â”œâ”€â”€ duckduckgotool.py
        â”œâ”€â”€ e2bcodetool.py
        â”œâ”€â”€ filecontentreadertool.py
        â”œâ”€â”€ filecreatortool.py
        â”œâ”€â”€ fileedittool.py
        â”œâ”€â”€ lintingtool.py
        â”œâ”€â”€ screenshottool.py
        â”œâ”€â”€ toolcreator.py
        â”œâ”€â”€ uvpackagemanager.py
        â””â”€â”€ webscrapertool.py

================================================
FILE: readme.md
================================================
# Claude Engineer v3 ğŸ¤–

A powerful self-improving AI Assistant designed for creating and managing AI tools with Claude 3.5. This framework enables Claude to generate and manage its own tools, continuously expanding its capabilities through conversation. Available both as a CLI and a modern web interface!

## History and Evolution
This project represents the third major iteration of Claude Engineer, building upon the success of Claude Engineer v2. Key improvements from previous versions include:
- Upgraded to Claude 3.5 Sonnet model
- Enhanced token management with Anthropic's new token counting API
- Self-improving tool creation system
- Streamlined conversation handling
- More precise token usage tracking and visualization
- Autonomous tool generation capabilities
- No need for automode since Claude can intelligently decide when to run tools automatically and sequentially.

## Description
Claude Engineer v3 is a sophisticated framework that allows Claude to expand its own capabilities through dynamic tool creation. During conversations, Claude can identify needs for new tools, design them, and implement them automatically. This self-improving architecture means the framework becomes more powerful the more you use it.


## Installation

For the best possible experience install uv

### macOS and Linux
```bash
# Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh
# Or using wget if curl is not available:
# wget -qO- https://astral.sh/uv/install.sh | sh

# Clone and setup
git clone https://github.com/Doriandarko/claude-engineer.git
cd claude-engineer
uv venv
source .venv/bin/activate

# Run web interface
uv run app.py

# Or run CLI
uv run ce3.py
```

### Windows
```powershell
# Install uv
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"

# Clone and setup
git clone https://github.com/Doriandarko/claude-engineer.git
cd claude-engineer
uv venv
.venv\Scripts\activate


# Run web interface
uv run app.py

# Or run CLI
uv run ce3.py
```


## Interface Options

### 1. Web Interface ğŸŒ
A sleek, modern web UI with features like:
- Real-time token usage visualization
- Image upload and analysis capabilities
- Markdown rendering with syntax highlighting
- Responsive design for all devices
- Tool usage indicators
- Clean, minimal interface

![Claude Engineer v3 Web Interface](ui.png)

To run the web interface:
```bash
# Using uv (recommended)
uv run app.py

# Or using traditional Python
python app.py

# Then open your browser to:
http://localhost:5000
```

### 2. Command Line Interface (CLI) ğŸ’»
A powerful terminal-based interface with:
- Rich text formatting
- Progress indicators
- Token usage visualization
- Direct tool interaction
- Detailed debugging output

To run the CLI:
```bash
# Using uv (recommended)
uv run ce3.py

# Or using traditional Python
python ce3.py
```

Choose the interface that best suits your workflow:
- Web UI: Great for visual work, image analysis, and a more modern experience
- CLI: Perfect for developers, system integration, and terminal workflows


## Self-Improvement Features
- ğŸ§  Autonomous tool identification and creation
- ğŸ”„ Dynamic capability expansion during conversations
- ğŸ¯ Smart tool dependency management
- ğŸ“ˆ Learning from tool usage patterns
- ğŸ” Automatic identification of capability gaps
- ğŸ› ï¸ Self-optimization of existing tools

## Core Features
- ğŸ”¨ Dynamic tool creation and loading
- ğŸ”„ Hot-reload capability for new tools
- ğŸ¨ Rich console interface with progress indicators
- ğŸ§© Tool abstraction framework with clean interfaces
- ğŸ“ Automated tool code generation
- ğŸ”Œ Easy integration with Claude 3.5 AI
- ğŸ’¬ Persistent conversation history with token management
- ğŸ› ï¸ Real-time tool usage display
- ğŸ”„ Automatic tool chaining support
- âš¡ Dynamic module importing system
- ğŸ“Š Advanced token tracking with Anthropic's token counting API
- ğŸ¯ Precise context window management
- ğŸ” Enhanced error handling and debugging
- ğŸ’¾ Conversation state management

## Project Structure
```
claude-engineer/
â”œâ”€â”€ app.py             # Web interface server
â”œâ”€â”€ ce3.py            # CLI interface
â”œâ”€â”€ config.py         # Configuration settings
â”œâ”€â”€ static/           # Web assets
â”‚   â”œâ”€â”€ css/         # Stylesheets
â”‚   â””â”€â”€ js/          # JavaScript files
â”œâ”€â”€ templates/        # HTML templates
â”œâ”€â”€ tools/           # Tool implementations
â”‚   â”œâ”€â”€ base.py      # Base tool class
â”‚   â””â”€â”€ ...         # Generated and custom tools
â””â”€â”€ prompts/         # System prompts
    â””â”€â”€ system_prompts.py
```

## Features by Interface

### Web Interface Features
- ğŸ–¼ï¸ Image upload and analysis with Claude Vision
- ğŸ“Š Visual token usage progress bar
- ğŸ¨ Clean, modern design with Tailwind CSS
- ğŸ“ Markdown rendering with syntax highlighting
- ğŸ”„ Real-time updates
- ğŸ“± Responsive design for all devices
- ğŸ–¥ï¸ Tool usage indicators
- âŒ¨ï¸ Command/Ctrl + Enter to send messages

### CLI Features
- ğŸ¨ Rich text formatting
- ğŸ“Š ASCII token usage bar
- ğŸ”„ Live progress indicators
- ğŸ› ï¸ Direct tool interaction
- ğŸ“ Detailed debugging output
- ğŸ’» Terminal-optimized interface

Choose the interface that best matches your workflow and preferences. Both interfaces provide access to the same powerful Claude Engineer capabilities, just presented in different ways.

## Key Components

### Assistant Class
The core Assistant class provides:
- Dynamic tool loading and management
- Real-time conversation handling with token tracking
- Automatic tool creation and validation
- Tool execution and chaining
- Rich console output with progress indicators
- Token usage optimization

### Configuration Options
The assistant supports various configuration options through the Config class:
- MODEL: Claude 3.5 Sonnet model specification
- MAX_TOKENS: Maximum tokens for individual responses
- MAX_CONVERSATION_TOKENS: Total token limit for conversations
- TOOLS_DIR: Directory for tool storage
- SHOW_TOOL_USAGE: Toggle tool usage display
- ENABLE_THINKING: Toggle thinking indicator
- DEFAULT_TEMPERATURE: Model temperature setting

## Requirements
- Python 3.8+
- Anthropic API Key (Claude 3.5 access)
- Required packages in `requirements.txt`
- Rich terminal support

## Contributing
Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

## License
MIT

## Acknowledgments
This project builds upon the foundations of Claude Engineer v2, enhancing its capabilities with self-improving tool generation and advanced token management.

## Built-in Tools
Claude Engineer v3 comes with a comprehensive set of pre-built tools:

### Core Tools
- ğŸ› ï¸ **Tool Creator** (`toolcreator`): Creates new tools based on natural language descriptions, enabling the framework's self-improvement capabilities.

### Development Tools
- ğŸ“¦ **UV Package Manager** (`uvpackagemanager`): Interface to the UV package manager for Python dependency management, supporting package installation, removal, updates, and virtual environment management.
- ğŸ **E2B Code Executor** (`e2bcodetool`): Securely executes Python code in a sandboxed environment powered by E2B. This tool enables Claude to write and run Python code directly, making it capable of data analysis, visualization, and complex computations. Requires an E2B API key available at [e2b.dev](https://e2b.dev/).
- ğŸ” **Linting Tool** (`lintingtool`): Runs the Ruff linter on Python files to detect and fix coding style or syntax issues, with support for automatic fixes and customizable rules.

### File System Tools
- ğŸ“‚ **Create Folders Tool** (`createfolderstool`): Creates new directories and nested directory structures with proper error handling and path validation.
- ğŸ“ **File Creator** (`filecreatortool`): Creates new files with specified content, supporting both text and binary files.
- ğŸ“– **File Content Reader** (`filecontentreadertool`): Reads content from multiple files simultaneously, with smart filtering of binary and system files.
- âœï¸ **File Edit** (`fileedittool`): Advanced file editing with support for full content replacement and partial edits.
- ğŸ”„ **Diff Editor** (`diffeditortool`): Performs precise text replacements in files by matching exact substrings.

### Web Tools
- ğŸ” **DuckDuckGo** (`duckduckgotool`): Performs web searches using DuckDuckGo.
- ğŸŒ **Web Scraper** (`webscrapertool`): Intelligently extracts readable content from web pages while removing unnecessary elements.
- ğŸŒ **Browser** (`browsertool`): Opens URLs in the system's default web browser.

### Utility Tools
- ğŸ“¸ **Screenshot Tool** (`screenshottool`): Captures screenshots of the entire screen or specific regions, returning base64-encoded images ready for Claude's vision capabilities.

Each tool is designed to be:
- Self-documenting with detailed descriptions
- Error-resistant with comprehensive error handling
- Composable for complex operations
- Secure with proper input validation
- Cross-platform compatible where applicable

The tools are dynamically loaded and can be extended during runtime through the Tool Creator, allowing the assistant to continuously expand its capabilities based on user needs.

## API Keys Required
1. **Anthropic API Key**: Required for Claude 3.5 access
2. **E2B API Key**: Required for Python code execution capabilities. Get your key at [e2b.dev](https://e2b.dev/)

Add these to your `.env` file:

```bash
ANTHROPIC_API_KEY=your_anthropic_key
E2B_API_KEY=your_e2b_key
```

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Doriandarko/claude-engineer&type=Date)](https://star-history.com/#Doriandarko/claude-engineer&Date)



================================================
FILE: app.py
================================================
from flask import Flask, render_template, request, jsonify, url_for
from ce3 import Assistant
import os
from werkzeug.utils import secure_filename
import base64
from config import Config

app = Flask(__name__, static_folder='static')
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# Ensure upload directory exists
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# Initialize the assistant
assistant = Assistant()

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    data = request.json
    message = data.get('message', '')
    image_data = data.get('image')  # Get the base64 image data
    
    # Prepare the message content
    if image_data:
        # Create a message with both text and image in correct order
        message_content = [
            {
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": "image/jpeg",  # We should detect this from the image
                    "data": image_data.split(',')[1] if ',' in image_data else image_data  # Remove data URL prefix if present
                }
            }
        ]
        
        # Only add text message if there is actual text
        if message.strip():
            message_content.append({
                "type": "text",
                "text": message
            })
    else:
        # Text-only message
        message_content = message
    
    try:
        # Handle the chat message with the appropriate content
        response = assistant.chat(message_content)
        
        # Get token usage from assistant
        token_usage = {
            'total_tokens': assistant.total_tokens_used,
            'max_tokens': Config.MAX_CONVERSATION_TOKENS
        }
        
        # Get the last used tool from the conversation history
        tool_name = None
        if assistant.conversation_history:
            for msg in reversed(assistant.conversation_history):
                if msg.get('role') == 'assistant' and msg.get('content'):
                    content = msg['content']
                    if isinstance(content, list):
                        for block in content:
                            if isinstance(block, dict) and block.get('type') == 'tool_use':
                                tool_name = block.get('name')
                                break
                    if tool_name:
                        break
        
        return jsonify({
            'response': response,
            'thinking': False,
            'tool_name': tool_name,
            'token_usage': token_usage
        })
        
    except Exception as e:
        return jsonify({
            'response': f"Error: {str(e)}",
            'thinking': False,
            'tool_name': None,
            'token_usage': None
        }), 200  # Return 200 even for errors to handle them gracefully in frontend

@app.route('/upload', methods=['POST'])
def upload_file():
    if 'file' not in request.files:
        return jsonify({'error': 'No file part'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No selected file'}), 400
    
    if file and file.filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.webp')):
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        # Get the actual media type
        media_type = file.content_type or 'image/jpeg'  # Default to jpeg if not detected
        
        # Convert image to base64
        with open(filepath, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        
        # Clean up the file
        os.remove(filepath)
        
        return jsonify({
            'success': True,
            'image_data': encoded_string,
            'media_type': media_type
        })
    
    return jsonify({'error': 'Invalid file type'}), 400

@app.route('/reset', methods=['POST'])
def reset():
    # Reset the assistant's conversation history
    assistant.reset()
    return jsonify({'status': 'success'})

if __name__ == '__main__':
    app.run(debug=False) 


================================================
FILE: ce3.py
================================================
# ce3.py
import anthropic
from rich.console import Console
from rich.markdown import Markdown
from rich.live import Live
from rich.spinner import Spinner
from rich.panel import Panel
from typing import List, Dict, Any
import importlib
import inspect
import pkgutil
import os
import json
import sys
import logging

from config import Config
from tools.base import BaseTool
from prompt_toolkit import prompt
from prompt_toolkit.styles import Style
from prompts.system_prompts import SystemPrompts

# Configure logging to only show ERROR level and above
logging.basicConfig(
    level=logging.ERROR,
    format='%(levelname)s: %(message)s'
)

class Assistant:
    """
    The Assistant class manages:
    - Loading of tools from a specified directory.
    - Interaction with the Anthropics API (message completion).
    - Handling user commands such as 'refresh' and 'reset'.
    - Token usage tracking and display.
    - Tool execution upon request from model responses.
    """

    def __init__(self):
        if not getattr(Config, 'ANTHROPIC_API_KEY', None):
            raise ValueError("No ANTHROPIC_API_KEY found in environment variables")

        # Initialize Anthropics client
        self.client = anthropic.Anthropic(api_key=Config.ANTHROPIC_API_KEY)

        self.conversation_history: List[Dict[str, Any]] = []
        self.console = Console()

        self.thinking_enabled = getattr(Config, 'ENABLE_THINKING', False)
        self.temperature = getattr(Config, 'DEFAULT_TEMPERATURE', 0.7)
        self.total_tokens_used = 0

        self.tools = self._load_tools()

    def _execute_uv_install(self, package_name: str) -> bool:
        """
        Execute the uvpackagemanager tool directly to install the missing package.
        Returns True if installation seems successful (no errors in output), otherwise False.
        """
        class ToolUseMock:
            name = "uvpackagemanager"
            input = {
                "command": "install",
                "packages": [package_name]
            }

        result = self._execute_tool(ToolUseMock())
        if "Error" not in result and "failed" not in result.lower():
            self.console.print("[green]The package was installed successfully.[/green]")
            return True
        else:
            self.console.print(f"[red]Failed to install {package_name}. Output:[/red] {result}")
            return False

    def _load_tools(self) -> List[Dict[str, Any]]:
        """
        Dynamically load all tool classes from the tools directory.
        If a dependency is missing, prompt the user to install it via uvpackagemanager.
        
        Returns:
            A list of tools (dicts) containing their 'name', 'description', and 'input_schema'.
        """
        tools = []
        tools_path = getattr(Config, 'TOOLS_DIR', None)

        if tools_path is None:
            self.console.print("[red]TOOLS_DIR not set in Config[/red]")
            return tools

        # Clear cached tool modules for fresh import
        for module_name in list(sys.modules.keys()):
            if module_name.startswith('tools.') and module_name != 'tools.base':
                del sys.modules[module_name]

        try:
            for module_info in pkgutil.iter_modules([str(tools_path)]):
                if module_info.name == 'base':
                    continue

                # Attempt loading the tool module
                try:
                    module = importlib.import_module(f'tools.{module_info.name}')
                    self._extract_tools_from_module(module, tools)
                except ImportError as e:
                    # Handle missing dependencies
                    missing_module = self._parse_missing_dependency(str(e))
                    self.console.print(f"\n[yellow]Missing dependency:[/yellow] {missing_module} for tool {module_info.name}")
                    user_response = input(f"Would you like to install {missing_module}? (y/n): ").lower()

                    if user_response == 'y':
                        success = self._execute_uv_install(missing_module)
                        if success:
                            # Retry loading the module after installation
                            try:
                                module = importlib.import_module(f'tools.{module_info.name}')
                                self._extract_tools_from_module(module, tools)
                            except Exception as retry_err:
                                self.console.print(f"[red]Failed to load tool after installation: {str(retry_err)}[/red]")
                        else:
                            self.console.print(f"[red]Installation of {missing_module} failed. Skipping this tool.[/red]")
                    else:
                        self.console.print(f"[yellow]Skipping tool {module_info.name} due to missing dependency[/yellow]")
                except Exception as mod_err:
                    self.console.print(f"[red]Error loading module {module_info.name}:[/red] {str(mod_err)}")
        except Exception as overall_err:
            self.console.print(f"[red]Error in tool loading process:[/red] {str(overall_err)}")

        return tools

    def _parse_missing_dependency(self, error_str: str) -> str:
        """
        Parse the missing dependency name from an ImportError string.
        """
        if "No module named" in error_str:
            parts = error_str.split("No module named")
            missing_module = parts[-1].strip(" '\"")
        else:
            missing_module = error_str
        return missing_module

    def _extract_tools_from_module(self, module, tools: List[Dict[str, Any]]) -> None:
        """
        Given a tool module, find and instantiate all tool classes (subclasses of BaseTool).
        Append them to the 'tools' list.
        """
        for name, obj in inspect.getmembers(module):
            if (inspect.isclass(obj) and issubclass(obj, BaseTool) and obj != BaseTool):
                try:
                    tool_instance = obj()
                    tools.append({
                        "name": tool_instance.name,
                        "description": tool_instance.description,
                        "input_schema": tool_instance.input_schema
                    })
                    self.console.print(f"[green]Loaded tool:[/green] {tool_instance.name}")
                except Exception as tool_init_err:
                    self.console.print(f"[red]Error initializing tool {name}:[/red] {str(tool_init_err)}")

    def refresh_tools(self):
        """
        Refresh the list of tools and show newly discovered tools.
        """
        current_tool_names = {tool['name'] for tool in self.tools}
        self.tools = self._load_tools()
        new_tool_names = {tool['name'] for tool in self.tools}
        new_tools = new_tool_names - current_tool_names

        if new_tools:
            self.console.print("\n")
            for tool_name in new_tools:
                tool_info = next((t for t in self.tools if t['name'] == tool_name), None)
                if tool_info:
                    description_lines = tool_info['description'].strip().split('\n')
                    formatted_description = '\n    '.join(line.strip() for line in description_lines)
                    self.console.print(f"[bold green]NEW[/bold green] ğŸ”§ [cyan]{tool_name}[/cyan]:\n    {formatted_description}")
        else:
            self.console.print("\n[yellow]No new tools found[/yellow]")

    def display_available_tools(self):
        """
        Print a list of currently loaded tools.
        """
        self.console.print("\n[bold cyan]Available tools:[/bold cyan]")
        tool_names = [tool['name'] for tool in self.tools]
        if tool_names:
            formatted_tools = ", ".join([f"ğŸ”§ [cyan]{name}[/cyan]" for name in tool_names])
        else:
            formatted_tools = "No tools available."
        self.console.print(formatted_tools)
        self.console.print("\n---")

    def _display_tool_usage(self, tool_name: str, input_data: Dict, result: str):
        """
        If SHOW_TOOL_USAGE is enabled, display the input and result of a tool execution.
        Handles special cases like image data and large outputs for cleaner display.
        """
        if not getattr(Config, 'SHOW_TOOL_USAGE', False):
            return

        # Clean up input data by removing any large binary/base64 content
        cleaned_input = self._clean_data_for_display(input_data)
        
        # Clean up result data
        cleaned_result = self._clean_data_for_display(result)

        tool_info = f"""[cyan]ğŸ“¥ Input:[/cyan] {json.dumps(cleaned_input, indent=2)}
[cyan]ğŸ“¤ Result:[/cyan] {cleaned_result}"""
        
        panel = Panel(
            tool_info,
            title=f"Tool used: {tool_name}",
            title_align="left",
            border_style="cyan",
            padding=(1, 2)
        )
        self.console.print(panel)

    def _clean_data_for_display(self, data):
        """
        Helper method to clean data for display by handling various data types
        and removing/replacing large content like base64 strings.
        """
        if isinstance(data, str):
            try:
                # Try to parse as JSON first
                parsed_data = json.loads(data)
                return self._clean_parsed_data(parsed_data)
            except json.JSONDecodeError:
                # If it's a long string, check for base64 patterns
                if len(data) > 1000 and ';base64,' in data:
                    return "[base64 data omitted]"
                return data
        elif isinstance(data, dict):
            return self._clean_parsed_data(data)
        else:
            return data

    def _clean_parsed_data(self, data):
        """
        Recursively clean parsed JSON/dict data, handling nested structures
        and replacing large data with placeholders.
        """
        if isinstance(data, dict):
            cleaned = {}
            for key, value in data.items():
                # Handle image data in various formats
                if key in ['data', 'image', 'source'] and isinstance(value, str):
                    if len(value) > 1000 and (';base64,' in value or value.startswith('data:')):
                        cleaned[key] = "[base64 data omitted]"
                    else:
                        cleaned[key] = value
                else:
                    cleaned[key] = self._clean_parsed_data(value)
            return cleaned
        elif isinstance(data, list):
            return [self._clean_parsed_data(item) for item in data]
        elif isinstance(data, str) and len(data) > 1000 and ';base64,' in data:
            return "[base64 data omitted]"
        return data

    def _execute_tool(self, tool_use):
        """
        Given a tool usage request (with tool name and inputs),
        dynamically load and execute the corresponding tool.
        """
        tool_name = tool_use.name
        tool_input = tool_use.input or {}
        tool_result = None

        try:
            module = importlib.import_module(f'tools.{tool_name}')
            tool_instance = self._find_tool_instance_in_module(module, tool_name)

            if not tool_instance:
                tool_result = f"Tool not found: {tool_name}"
            else:
                # Execute the tool with the provided input
                try:
                    result = tool_instance.execute(**tool_input)
                    # Keep structured data intact
                    tool_result = result
                except Exception as exec_err:
                    tool_result = f"Error executing tool '{tool_name}': {str(exec_err)}"
        except ImportError:
            tool_result = f"Failed to import tool: {tool_name}"
        except Exception as e:
            tool_result = f"Error executing tool: {str(e)}"

        # Display tool usage with proper handling of structured data
        self._display_tool_usage(tool_name, tool_input, 
            json.dumps(tool_result) if not isinstance(tool_result, str) else tool_result)
        return tool_result

    def _find_tool_instance_in_module(self, module, tool_name: str):
        """
        Search a given module for a tool class matching tool_name and return an instance of it.
        """
        for name, obj in inspect.getmembers(module):
            if (inspect.isclass(obj) and issubclass(obj, BaseTool) and obj != BaseTool):
                candidate_tool = obj()
                if candidate_tool.name == tool_name:
                    return candidate_tool
        return None

    def _display_token_usage(self, usage):
        """
        Display a visual representation of token usage and remaining tokens.
        Uses only the tracked total_tokens_used.
        """
        used_percentage = (self.total_tokens_used / Config.MAX_CONVERSATION_TOKENS) * 100
        remaining_tokens = max(0, Config.MAX_CONVERSATION_TOKENS - self.total_tokens_used)

        self.console.print(f"\nTotal used: {self.total_tokens_used:,} / {Config.MAX_CONVERSATION_TOKENS:,}")

        bar_width = 40
        filled = int(used_percentage / 100 * bar_width)
        bar = "â–ˆ" * filled + "â–‘" * (bar_width - filled)

        color = "green"
        if used_percentage > 75:
            color = "yellow"
        if used_percentage > 90:
            color = "red"

        self.console.print(f"[{color}][{bar}] {used_percentage:.1f}%[/{color}]")

        if remaining_tokens < 20000:
            self.console.print(f"[bold red]Warning: Only {remaining_tokens:,} tokens remaining![/bold red]")

        self.console.print("---")

    def _get_completion(self):
        """
        Get a completion from the Anthropic API.
        Handles both text-only and multimodal messages.
        """
        try:
            response = self.client.messages.create(
                model=Config.MODEL,
                max_tokens=min(
                    Config.MAX_TOKENS,
                    Config.MAX_CONVERSATION_TOKENS - self.total_tokens_used
                ),
                temperature=self.temperature,
                tools=self.tools,
                messages=self.conversation_history,
                system=f"{SystemPrompts.DEFAULT}\n\n{SystemPrompts.TOOL_USAGE}"
            )

            # Update token usage based on response usage
            if hasattr(response, 'usage') and response.usage:
                message_tokens = response.usage.input_tokens + response.usage.output_tokens
                self.total_tokens_used += message_tokens
                self._display_token_usage(response.usage)

            if self.total_tokens_used >= Config.MAX_CONVERSATION_TOKENS:
                self.console.print("\n[bold red]Token limit reached! Please reset the conversation.[/bold red]")
                return "Token limit reached! Please type 'reset' to start a new conversation."

            if response.stop_reason == "tool_use":
                self.console.print("\n[bold yellow]  Handling Tool Use...[/bold yellow]\n")

                tool_results = []
                if getattr(response, 'content', None) and isinstance(response.content, list):
                    # Execute each tool in the response content
                    for content_block in response.content:
                        if content_block.type == "tool_use":
                            result = self._execute_tool(content_block)
                            
                            # Handle structured data (like image blocks) vs text
                            if isinstance(result, (list, dict)):
                                tool_results.append({
                                    "type": "tool_result",
                                    "tool_use_id": content_block.id,
                                    "content": result  # Keep structured data intact
                                })
                            else:
                                # Convert text results to proper content blocks
                                tool_results.append({
                                    "type": "tool_result",
                                    "tool_use_id": content_block.id,
                                    "content": [{"type": "text", "text": str(result)}]
                                })

                    # Append tool usage to conversation and continue
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": response.content
                    })
                    self.conversation_history.append({
                        "role": "user",
                        "content": tool_results
                    })
                    return self._get_completion()  # Recursive call to continue the conversation

                else:
                    self.console.print("[red]No tool content received despite 'tool_use' stop reason.[/red]")
                    return "Error: No tool content received"

            # Final assistant response
            if (getattr(response, 'content', None) and 
                isinstance(response.content, list) and 
                response.content):
                final_content = response.content[0].text
                self.conversation_history.append({
                    "role": "assistant",
                    "content": response.content
                })
                return final_content
            else:
                self.console.print("[red]No content in final response.[/red]")
                return "No response content available."

        except Exception as e:
            logging.error(f"Error in _get_completion: {str(e)}")
            return f"Error: {str(e)}"

    def chat(self, user_input):
        """
        Process a chat message from the user.
        user_input can be either a string (text-only) or a list (multimodal message)
        """
        # Handle special commands only for text-only messages
        if isinstance(user_input, str):
            if user_input.lower() == 'refresh':
                self.refresh_tools()
                return "Tools refreshed successfully!"
            elif user_input.lower() == 'reset':
                self.reset()
                return "Conversation reset!"
            elif user_input.lower() == 'quit':
                return "Goodbye!"

        try:
            # Add user message to conversation history
            self.conversation_history.append({
                "role": "user",
                "content": user_input  # This can be either string or list
            })

            # Show thinking indicator if enabled
            if self.thinking_enabled:
                with Live(Spinner('dots', text='Thinking...', style="cyan"), 
                         refresh_per_second=10, transient=True):
                    response = self._get_completion()
            else:
                response = self._get_completion()

            return response

        except Exception as e:
            logging.error(f"Error in chat: {str(e)}")
            return f"Error: {str(e)}"

    def reset(self):
        """
        Reset the assistant's memory and token usage.
        """
        self.conversation_history = []
        self.total_tokens_used = 0
        self.console.print("\n[bold green]ğŸ”„ Assistant memory has been reset![/bold green]")

        welcome_text = """
# Claude Engineer v3. A self-improving assistant framework with tool creation

Type 'refresh' to reload available tools
Type 'reset' to clear conversation history
Type 'quit' to exit

Available tools:
"""
        self.console.print(Markdown(welcome_text))
        self.display_available_tools()


def main():
    """
    Entry point for the assistant CLI loop.
    Provides a prompt for user input and handles 'quit' and 'reset' commands.
    """
    console = Console()
    style = Style.from_dict({'prompt': 'orange'})

    try:
        assistant = Assistant()
    except ValueError as e:
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        console.print("Please ensure ANTHROPIC_API_KEY is set correctly.")
        return

    welcome_text = """
# Claude Engineer v3. A self-improving assistant framework with tool creation

Type 'refresh' to reload available tools
Type 'reset' to clear conversation history
Type 'quit' to exit

Available tools:
"""
    console.print(Markdown(welcome_text))
    assistant.display_available_tools()

    while True:
        try:
            user_input = prompt("You: ", style=style).strip()

            if user_input.lower() == 'quit':
                console.print("\n[bold blue]ğŸ‘‹ Goodbye![/bold blue]")
                break
            elif user_input.lower() == 'reset':
                assistant.reset()
                continue

            response = assistant.chat(user_input)
            console.print("\n[bold purple]Claude Engineer:[/bold purple]")
            if isinstance(response, str):
                safe_response = response.replace('[', '\\[').replace(']', '\\]')
                console.print(safe_response)
            else:
                console.print(str(response))

        except KeyboardInterrupt:
            continue
        except EOFError:
            break


if __name__ == "__main__":
    main()


================================================
FILE: config.py
================================================
from pathlib import Path
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
    MODEL = "claude-3-5-sonnet-20241022"
    MAX_TOKENS = 8000
    MAX_CONVERSATION_TOKENS = 200000  # Maximum tokens per conversation

    # Paths
    BASE_DIR = Path(__file__).parent
    TOOLS_DIR = BASE_DIR / "tools"
    PROMPTS_DIR = BASE_DIR / "prompts"

    # Assistant Configuration
    ENABLE_THINKING = True
    SHOW_TOOL_USAGE = True
    DEFAULT_TEMPERATURE = 0.7



================================================
FILE: pyproject.toml
================================================
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "ce3"
version = "0.1.0"
description = "A self-improving assistant framework with tool creation capabilities"
readme = "README.md"
requires-python = ">=3.9"
license = { text = "MIT" }
authors = [{ name = "Your Name", email = "your.email@example.com" }]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Topic :: Software Development :: Libraries :: Python Modules",
]
dependencies = [
    "anthropic",
    "python-dotenv",
    "rich",
    "requests",
    "beautifulsoup4",
    "validators>=0.34.0",
    "PyAutoGUI",
    "Pillow",
    "prompt-toolkit",
    "matplotlib>=3.9.2",
    "flask>=3.0.3",
    "werkzeug>=3.1.2",
    "markdownify>=0.14.1",
    "protego>=0.3.1",
    "readability-lxml>=0.8.1",
    "e2b-code-interpreter>=1.0.3",
]

[project.optional-dependencies]
dev = [
    "pytest",
    "pytest-cov",
    "black",
    "ruff",
    "mypy",
    "pre-commit",
    "types-requests",
]

[project.urls]
Homepage = "https://github.com/yourusername/cev3"
Repository = "https://github.com/yourusername/cev3"
Documentation = "https://github.com/yourusername/cev3#readme"
"Bug Tracker" = "https://github.com/yourusername/cev3/issues"

[tool.hatch]
version.path = "cev3/__init__.py"

[tool.ruff]
line-length = 88
target-version = "py39"
select = [
    "E",   # pycodestyle errors
    "F",   # pyflakes
    "I",   # isort
    "B",   # flake8-bugbear
    "C4",  # flake8-comprehensions
    "UP",  # pyupgrade
    "RUF", # ruff-specific rules
]
ignore = []

[tool.ruff.isort]
known-first-party = ["cev3"]

[tool.ruff.flake8-tidy-imports]
ban-relative-imports = "all"

[tool.black]
line-length = 88
target-version = ["py39"]
include = '\.pyi?$'

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
check_untyped_defs = true
disallow_any_generics = true
disallow_incomplete_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true

[[tool.mypy.overrides]]
module = ["wikipedia.*", "pyautogui.*"]
ignore_missing_imports = true

[tool.pytest.ini_options]
minversion = "6.0"
addopts = "-ra -q --cov=cev3 --cov-report=term-missing"
testpaths = ["tests"]

[tool.uv.workspace]
members = ["testfolder"]

[project.scripts]
cev3 = "cev3.cev3:main"



================================================
FILE: requirements.txt
================================================
flask==3.0.0
anthropic>=0.18.1
beautifulsoup4>=4.12.3
markdownify>=0.14.1
pillow>=10.2.0
protego>=0.3.1
pyautogui>=0.9.54
python-dotenv>=1.0.1
readability-lxml>=0.8.1
requests>=2.31.0
rich>=13.7.0
validators>=0.22.0
werkzeug>=3.0.1
prompt-toolkit>=3.0.43
matplotlib>=3.9.2


================================================
FILE: test.py
================================================
from typing import List
import unittest

def calculate_sum(numbers: List[float]) -> float:
    """
    Calculate the sum of a list of numbers.
    
    Args:
        numbers (List[float]): A list of numbers to sum
        
    Returns:
        float: The sum of all numbers in the list
        
    Raises:
        ValueError: If the input list is empty
    """
    if not numbers:
        raise ValueError("Cannot calculate sum of an empty list")
    return sum(numbers)

def calculate_median(numbers: List[float]) -> float:
    """
    Calculate the median of a list of numbers.
    
    Args:
        numbers (List[float]): A list of numbers to find the median of
        
    Returns:
        float: The median value of the list
        
    Raises:
        ValueError: If the input list is empty
    """
    if not numbers:
        raise ValueError("Cannot calculate median of an empty list")
    
    sorted_numbers = sorted(numbers)
    n = len(sorted_numbers)
    mid = n // 2
    
    if n % 2 == 0:
        return (sorted_numbers[mid-1] + sorted_numbers[mid]) / 2
    else:
        return sorted_numbers[mid]

def main() -> None:
    """Main function to demonstrate the usage of calculate_sum and calculate_median."""
    try:
        numbers = [1, 2, 3, 4, 5]
        total = calculate_sum(numbers)
        median = calculate_median(numbers)
        print(f"The sum is: {total}")
        print(f"The median is: {median}")
    except ValueError as e:
        print(f"Error: {e}")

class TestCalculateSum(unittest.TestCase):
    """Test cases for the calculate_sum function."""
    
    def test_normal_list(self):
        """Test with a normal list of numbers."""
        self.assertEqual(calculate_sum([1, 2, 3, 4, 5]), 15)
        
    def test_float_numbers(self):
        """Test with floating point numbers."""
        self.assertAlmostEqual(calculate_sum([1.5, 2.5, 3.5]), 7.5)
        
    def test_empty_list(self):
        """Test that empty list raises ValueError."""
        with self.assertRaises(ValueError):
            calculate_sum([])
            
    def test_negative_numbers(self):
        """Test with negative numbers."""
        self.assertEqual(calculate_sum([-1, -2, -3]), -6)

class TestCalculateMedian(unittest.TestCase):
    """Test cases for the calculate_median function."""
    
    def test_odd_length_list(self):
        """Test median with odd number of elements."""
        self.assertEqual(calculate_median([1, 2, 3, 4, 5]), 3)
        
    def test_even_length_list(self):
        """Test median with even number of elements."""
        self.assertEqual(calculate_median([1, 2, 3, 4]), 2.5)
        
    def test_unordered_list(self):
        """Test median with unordered list."""
        self.assertEqual(calculate_median([5, 2, 1, 4, 3]), 3)
        
    def test_empty_list(self):
        """Test that empty list raises ValueError."""
        with self.assertRaises(ValueError):
            calculate_median([])
            
    def test_negative_numbers(self):
        """Test with negative numbers."""
        self.assertEqual(calculate_median([-1, -2, -3]), -2)

if __name__ == "__main__":
    main()
    # Run the tests
    unittest.main(argv=[''], exit=False)



================================================
FILE: .env.example
================================================
ANTHROPIC_API_KEY=your_anthropic_api_key
E2B_API_KEY=your_e2b_api_key # optional


================================================
FILE: Claude-Eng-v2/readme.md
================================================
# ğŸ¤– Claude Engineer

Claude Engineer is an advanced interactive command-line interface (CLI) that harnesses the power of Anthropic's Claude 3 and Claude 3.5 models to assist with a wide range of software development tasks. This tool seamlessly combines the capabilities of state-of-the-art large language models with practical file system operations, web search functionality, intelligent code analysis, and execution capabilities.

## NEW

TTS using 11labs WebSockets and audio streaming.
Type
```
11labs on
```
to use TTS and 11labs off to return to regualr mode.

Voice mode ğŸ—£ï¸: Now you can talk to the Engineer directly without even touching your keyboard.

Type
```
voice
```
to enter voice mode.

Say "exit voice mode" to return to regular text.

If you want to use your voice and 11 labs at the same time, first activate 11labs then type voice to use your voice. 

Prompt caching. Make sure you udpate your Anthropic python package before running the script.
```
pip install --upgrade anthropic
```

## âœ¨ Features

- ğŸ’¬ Interactive chat interface with Claude 3 and Claude 3.5 models
- ğŸ“ Comprehensive file system operations (create folders, files, read/write files)
- ğŸ” Web search capabilities using Tavily API for up-to-date information
- ğŸŒˆ Enhanced syntax highlighting for code snippets
- ğŸ—ï¸ Intelligent project structure creation and management
- ğŸ§ Advanced code analysis and improvement suggestions
- ğŸ–¼ï¸ Image analysis capabilities with support for drag and drop in the terminal
- ğŸš€ Improved automode for efficient autonomous task completion
- ğŸ”„ Robust iteration tracking and management in automode
- ğŸ“Š Precise diff-based file editing for controlled code modifications
- ğŸ›¡ï¸ Enhanced error handling and detailed output for tool usage
- ğŸ¨ Color-coded terminal output using Rich library for improved readability
- ğŸ”§ Detailed logging of tool usage and results
- ğŸ” Improved file editing workflow with separate read and apply steps
- ğŸ§  Dynamic system prompt updates based on automode status
- ğŸ” TOOLCHECKERMODEL for validating tool usage and outputs
- ğŸ“ CODEEDITORMODEL for specialized code editing tasks
- ğŸ–¥ï¸ CODEEXECUTIONMODEL for analyzing code execution results
- ğŸ“Š Token usage tracking (input, output, and total) for each model, with improved visualization using tables
- ğŸªŸ Remaining context window display
- ğŸ’¾ Chat log saving capability
- ğŸ”’ Enhanced code execution capabilities with isolated virtual environment
- ğŸ”„ Process management for long-running code executions
- ğŸ“š Multi-file reading capability for efficient handling of multiple files simultaneously

## ğŸ› ï¸ Installation

1. Clone this repository:
   ```
   git clone https://github.com/doriandarko/claude-engineer.git
   cd claude-engineer
   ```

2. Install the required dependencies:
   ```
   pip install -r requirements.txt
   ```

3. Set up your environment variables:
   - Create a `.env` file in the project root directory
   - Add the following environment variables:
     ```
     ANTHROPIC_API_KEY=your_anthropic_api_key
     TAVILY_API_KEY=your_tavily_api_key
     ```

4. Set up the virtual environment for code execution:
   Engineer will create a virtual environment to run code the first time it executes a piece of code.
   This is just for you if you want to run the main script in a virtual environment rather than in your default one.
   ```
   python -m venv code_execution_env
   source code_execution_env/bin/activate  # On Windows, use: code_execution_env\Scripts\activate
   pip install -r requirements.txt
   deactivate
   ```

## ğŸ”§ Virtual Environment Setup

Claude Engineer uses a dedicated virtual environment for code execution to ensure isolation and security. The virtual environment is automatically created the first time you run a piece of code. However, if you want to set it up manually or customize it, follow these steps:

1. Create the virtual environment:
   ```
   python -m venv code_execution_env
   ```

2. Activate the virtual environment:
   - On Windows:
     ```
     code_execution_env\Scripts\activate
     ```
   - On macOS and Linux:
     ```
     source code_execution_env/bin/activate
     ```

3. Install the required dependencies:
   ```
   pip install -r requirements.txt
   ```

4. Deactivate the virtual environment when you're done:
   ```
   deactivate
   ```

The code_execution_env virtual environment will be used for all code execution tasks, ensuring a consistent and isolated environment for running user code.

## ğŸš€ Usage

Run the main script to start the Claude Engineer interface:

```
python main.py
```

Once started, you can interact with Claude Engineer by typing your queries or commands. Some example interactions:

- "Create a new Python project structure for a web application"
- "Explain the code in file.py and suggest improvements"
- "Search for the latest best practices in React development"
- "Help me debug this error: [paste your error message]"
- "Analyze this image and describe its contents"
- "Execute this Python code and analyze the results"
- "Read multiple files: file1.py, file2.py, file3.py"

Special commands:
- Type 'exit' to end the conversation and close the application.
- Type 'image' to include an image in your message for analysis.
- Type 'reset' to reset the entire conversation without restarting the script.
- Type 'automode number' to enter Autonomous mode with a specific number of iterations.
- Type 'save chat' to save the current chat log.
- Press Ctrl+C at any time to exit the automode and return to regular chat.

After each interaction, Claude Engineer will display:
- Token usage (input, output, and total) for the current model
- Remaining context window size

### Code Execution and Process Management

Claude Engineer now supports executing code in an isolated 'code_execution_env' virtual environment:

1. Use the `execute_code` tool to run Python code safely in the isolated environment.
2. Long-running processes can be managed using the process ID returned by `execute_code`.
3. The CODEEXECUTIONMODEL analyzes execution results and provides insights.

### Using Different AI Models

Claude Engineer utilizes multiple specialized AI models:

- MAINMODEL: Claude 3 or Claude 3.5 for general interactions
- TOOLCHECKERMODEL: Validates tool usage and outputs
- CODEEDITORMODEL: Performs specialized code editing tasks
- CODEEXECUTIONMODEL: Analyzes code execution results

The script automatically selects the appropriate model based on the task.

### ğŸ¤– Improved Automode

The enhanced automode allows Claude to work autonomously on complex tasks with greater efficiency and control. When in automode:

1. Claude sets clear, achievable goals based on your request.
2. It works through these goals one by one, using available tools as needed.
3. Claude provides regular updates on its progress, including the current iteration count.
4. Automode continues until goals are completed or the maximum number of iterations is reached.
5. You can specify the maximum number of iterations when entering automode (default is 25).
6. Claude dynamically adjusts its approach based on progress and obstacles encountered.
7. The TOOLCHECKERMODEL validates tool usage and outputs for increased reliability.

To use automode:
1. Type 'automode number' when prompted for input, where number is the maximum number of iterations.
2. Provide your request when prompted.
3. Claude will work autonomously, providing updates after each iteration.
4. Automode exits when the task is completed, after reaching the maximum number of iterations, or when you press Ctrl+C.

### ğŸ“Š Enhanced Diff-based File Editing

Claude Engineer now supports an improved diff-based file editing system, allowing for more precise and controlled modifications to existing files. The new workflow includes:

1. Reading the entire content of a file using the `edit_and_apply` function without providing new content.
2. Applying changes to the file using the `edit_and_apply` function with new content, which shows a detailed diff of the proposed changes.
3. Utilizing the CODEEDITORMODEL for specialized code editing tasks, ensuring high-quality modifications.

When editing files, Claude will:

1. Show a detailed diff of the proposed changes, highlighting additions, removals, and unchanged lines with color coding using the Rich library.
2. Focus on adding new code or modifying existing code without unnecessarily removing functionality.
3. Provide a summary of lines added and removed.
4. Apply changes carefully to avoid duplicates and unwanted replacements.
5. Support various editing scenarios, including targeted changes, appending content, inserting at the beginning, and replacing entire file contents.
6. Use the CODEEDITORMODEL to ensure code changes adhere to best practices and maintain consistency.

This feature enhances Claude's ability to make targeted improvements to your codebase while maintaining the integrity of existing functionality.

### ğŸ§  Dynamic System Prompt

The system prompt is now dynamically updated based on whether the script is in automode or not. This allows for more tailored instructions and behavior depending on the current operating mode:

1. In regular mode, Claude focuses on providing helpful responses and using tools as needed.
2. In automode, Claude is instructed to work autonomously, set goals, and provide regular updates on progress.
3. The system prompt adapts to the specific task at hand, optimizing Claude's performance for each scenario.
4. The system prompt now includes file context for enhanced token management.

The dynamic system prompt enhances Claude's ability to adapt to different scenarios and provide more relevant assistance.

### ğŸ“Š Token Management and Visualization

Claude Engineer now features improved token management and visualization:

1. Enhanced token management using file context in the system prompt.
2. Improved token visualization using a table format.
3. Display of input, output, and total token usage for each model interaction.
4. Visualization of remaining context window size.

These improvements provide better insights into token usage and help manage conversations more effectively.

### ğŸ”§ Available Tools

Claude Engineer comes with a set of powerful tools to assist with various tasks:

1. create_folder: Create a new folder at a specified path.
2. create_file: Create a new file at a specified path with content.
3. edit_and_apply: Read the contents of a file, and optionally apply changes.
4. read_file: Read the contents of a file at the specified path.
5. read_multiple_files: Read the contents of multiple files at specified paths.
6. list_files: List all files and directories in the specified folder.
7. tavily_search: Perform a web search using Tavily API to get up-to-date information.
8. execute_code: Run Python code in an isolated virtual environment.
9. stop_process: Manage and stop long-running code executions.
10. TOOLCHECKERMODEL: Validate tool usage and outputs for increased reliability.
11. CODEEDITORMODEL: Perform specialized code editing tasks with high precision.
12. CODEEXECUTIONMODEL: Analyze code execution results and provide insights.

These tools allow Claude to interact with the file system, manage project structures, gather information from the web, perform advanced code editing, and execute code safely.

### ğŸ–¼ï¸ Image Analysis

Claude Engineer now supports image analysis capabilities. To use this feature:

1. Type 'image' when prompted for input.
2. Drag and drop your image file into the terminal or provide the file path.
3. Provide a prompt or question about the image.
4. Claude will analyze the image and respond to your query.

This feature enables Claude to assist with tasks involving visual data, such as analyzing diagrams, screenshots, or any other images relevant to your development work.

### ğŸ›¡ï¸ Error Handling and Recovery

Claude Engineer implements robust error handling and recovery mechanisms:

1. Graceful handling of API errors and network issues.
2. Automatic retries for transient failures.
3. Clear error messages and suggestions for user action when needed.
4. Logging of errors for debugging and improvement purposes.
5. Ability to recover and continue operation after non-critical errors.
6. Safe termination of long-running processes when needed.

These features ensure a smooth and reliable user experience, even in the face of unexpected issues or complex code executions.

### ğŸ’¾ Chat Log Saving

You can save the current chat log at any time during your interaction with Claude Engineer:

1. Type 'save' when prompted for input.
2. The chat log will be saved to a file in the current directory with a timestamp in the filename.
3. You can review these logs later for reference or to continue previous conversations.

## ğŸ§  AI Models and Specialized Agents

Claude Engineer utilizes multiple AI models to provide specialized functionality:

1. MAINMODEL (Claude 3 or Claude 3.5): Handles general interactions and task processing.
2. TOOLCHECKERMODEL: Validates the usage and outputs of various tools to ensure reliability.
3. CODEEDITORMODEL: Specializes in code editing tasks, ensuring high-quality modifications.
4. CODEEXECUTIONMODEL: Analyzes code execution results and provides insights.

These models work together to provide a comprehensive and intelligent development assistance experience.

## Workflow Diagram

```mermaid
graph TD
    A[Start] --> B[Initialize]
    B --> C{User Input}
    
    C -->|"exit"| D[End]
    C -->|"reset"| E[Reset Conversation]
    C -->|"save chat"| F[Save Chat to Markdown]
    C -->|"image"| G[Process Image]
    C -->|"automode"| H[Enter Automode]
    C -->|Other| I[Regular Chat]
    
    E --> C
    F --> C
    G --> J[chat_with_claude]
    H --> K[Automode Loop]
    I --> J
    
    J --> L{Tool Use?}
    L -->|Yes| M[Execute Tool]
    L -->|No| N[Generate Response]
    
    M --> O[Tool Checker]
    O --> N
    
    N --> P[Update Conversation History]
    P --> Q[Display Token Usage]
    Q --> C
    
    subgraph Memory Management
        R[Conversation History]
        S[File Contents]
        T[Code Editor Memory]
    end
    
    subgraph Models
        U[MAINMODEL - Claude-3.5-Sonnet]
        V[TOOLCHECKERMODEL - Claude-3.5-Sonnet]
        W[CODEEDITORMODEL - Claude-3.5-Sonnet]
        X[CODEEXECUTIONMODEL - Claude-3-Haiku]
    end
    
    subgraph Tools
        Y[create_folder]
        Z[create_file]
        AA[edit_and_apply]
        AB[execute_code]
        AC[stop_process]
        AD[read_file]
        AE[list_files]
        AF[tavily_search]
        AG[read_multiple_files]
    end
    
    J --> R
    J --> S
    J --> T
    J --> U
    O --> V
    AA --> W
    AB --> X
    M --> Y
    M --> Z
    M --> AA
    M --> AB
    M --> AC
    M --> AD
    M --> AE
    M --> AF
    M --> AG
```


## ğŸ‘¥ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

## ğŸ¦™ Ollama eng is here

You can now have the power of this script, completely locally using Ollama and any of the supported function calling models:
Llama 3.1
Mistral Nemo
Firefunction v2
Command-R +

Before running make sure you install the latest version of the Ollama app and 

```
pip install ollama
```

Then

```
python ollama-eng.py
```

### ğŸš¨Important note on safety when using Ollama Engineer!

Be extra careful if you ever let these local models run code on your machine, especially using the executing code tool. It may brick your machine. I disabled the tool execution completely for OLLAMA engineer but if you want to implement it again based on the original script use at your own discretion.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Doriandarko/claude-engineer&type=Date)](https://star-history.com/#Doriandarko/claude-engineer&Date)



================================================
FILE: Claude-Eng-v2/ollama-eng.py
================================================
import os
from dotenv import load_dotenv
import json
from tavily import TavilyClient
import re
import ollama
import asyncio
import difflib
import time
import logging
from typing import Optional, Dict, Any
from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax
from rich.markdown import Markdown
import asyncio
import aiohttp
from prompt_toolkit import PromptSession
from prompt_toolkit.styles import Style

async def get_user_input(prompt="You: "):
    style = Style.from_dict({
        'prompt': 'cyan bold',
    })
    session = PromptSession(style=style)
    return await session.prompt_async(prompt, multiline=False)
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
import datetime
# Load environment variables from .env file
load_dotenv()

# Initialize the Ollama client
client = ollama.AsyncClient()

# Initialize the Tavily client
tavily_api_key = os.getenv("TAVILY_API_KEY")
if not tavily_api_key:
    raise ValueError("TAVILY_API_KEY not found in environment variables")
tavily = TavilyClient(api_key=tavily_api_key)

console = Console()



# Set up the conversation memory (maintains context for MAINMODEL)
conversation_history = []

# Store file contents (part of the context for MAINMODEL)
file_contents = {}

# Code editor memory (maintains some context for CODEEDITORMODEL between calls)
code_editor_memory = []

# Files already present in code editor's context
code_editor_files = set()

# automode flag
automode = False

# Store file contents
file_contents = {}

# Global dictionary to store running processes
running_processes = {}

# Constants
CONTINUATION_EXIT_PHRASE = "AUTOMODE_COMPLETE"
MAX_CONTINUATION_ITERATIONS = 25
MAX_CONTEXT_TOKENS = 200000  # Reduced to 200k tokens for context window

# Models
# Models that maintain context memory across interactions
MAINMODEL = "mistral-nemo"  # Maintains conversation history and file contents

# Models that don't maintain context (memory is reset after each call)
TOOLCHECKERMODEL = "mistral-nemo"
CODEEDITORMODEL = "mistral-nemo"

# System prompts
BASE_SYSTEM_PROMPT = """
You are Ollama Engineer, an AI assistant powered Ollama models, specialized in software development with access to a variety of tools and the ability to instruct and direct a coding agent and a code execution one. Your capabilities include:

1. Creating and managing project structures
2. Writing, debugging, and improving code across multiple languages
3. Providing architectural insights and applying design patterns
4. Staying current with the latest technologies and best practices
5. Analyzing and manipulating files within the project directory
6. Performing web searches for up-to-date information
7. Executing code and analyzing its output within an isolated 'code_execution_env' virtual environment
8. Managing and stopping running processes started within the 'code_execution_env'

Available tools and their optimal use cases:

1. create_folder: Create new directories in the project structure.
2. create_file: Generate new files with specified content. Strive to make the file as complete and useful as possible.
3. edit_and_apply: Examine and modify existing files by instructing a separate AI coding agent. You are responsible for providing clear, detailed instructions to this agent. When using this tool:
   - Provide comprehensive context about the project, including recent changes, new variables or functions, and how files are interconnected.
   - Clearly state the specific changes or improvements needed, explaining the reasoning behind each modification.
   - Include ALL the snippets of code to change, along with the desired modifications.
   - Specify coding standards, naming conventions, or architectural patterns to be followed.
   - Anticipate potential issues or conflicts that might arise from the changes and provide guidance on how to handle them.
4. execute_code: Run Python code exclusively in the 'code_execution_env' virtual environment and analyze its output. Use this when you need to test code functionality or diagnose issues. Remember that all code execution happens in this isolated environment. This tool now returns a process ID for long-running processes.
5. stop_process: Stop a running process by its ID. Use this when you need to terminate a long-running process started by the execute_code tool.
6. read_file: Read the contents of an existing file.
7. read_multiple_files: Read the contents of multiple existing files at once. Use this when you need to examine or work with multiple files simultaneously.
8. list_files: List all files and directories in a specified folder.
9. tavily_search: Perform a web search using the Tavily API for up-to-date information.

Tool Usage Guidelines:
- Always use the most appropriate tool for the task at hand.
- Provide detailed and clear instructions when using tools, especially for edit_and_apply.
- After making changes, always review the output to ensure accuracy and alignment with intentions.
- Use execute_code to run and test code within the 'code_execution_env' virtual environment, then analyze the results.
- For long-running processes, use the process ID returned by execute_code to stop them later if needed.
- Proactively use tavily_search when you need up-to-date information or additional context.
- When working with multiple files, consider using read_multiple_files for efficiency.

Error Handling and Recovery:
- If a tool operation fails, carefully analyze the error message and attempt to resolve the issue.
- For file-related errors, double-check file paths and permissions before retrying.
- If a search fails, try rephrasing the query or breaking it into smaller, more specific searches.
- If code execution fails, analyze the error output and suggest potential fixes, considering the isolated nature of the environment.
- If a process fails to stop, consider potential reasons and suggest alternative approaches.

Project Creation and Management:
1. Start by creating a root folder for new projects.
2. Create necessary subdirectories and files within the root folder.
3. Organize the project structure logically, following best practices for the specific project type.

Always strive for accuracy, clarity, and efficiency in your responses and actions. Your instructions must be precise and comprehensive. If uncertain, use the tavily_search tool or admit your limitations. When executing code, always remember that it runs in the isolated 'code_execution_env' virtual environment. Be aware of any long-running processes you start and manage them appropriately, including stopping them when they are no longer needed.

When using tools:
1. Carefully consider if a tool is necessary before using it.
2. Ensure all required parameters are provided and valid.
3. Handle both successful results and errors gracefully.
4. Provide clear explanations of tool usage and results to the user.

Remember, you are an AI assistant, and your primary goal is to help the user accomplish their tasks effectively and efficiently while maintaining the integrity and security of their development environment.
"""

AUTOMODE_SYSTEM_PROMPT = """
You are currently in automode. Follow these guidelines:

1. Goal Setting:
   - Set clear, achievable goals based on the user's request.
   - Break down complex tasks into smaller, manageable goals.

2. Goal Execution:
   - Work through goals systematically, using appropriate tools for each task.
   - Utilize file operations, code writing, and web searches as needed.
   - Always read a file before editing and review changes after editing.

3. Progress Tracking:
   - Provide regular updates on goal completion and overall progress.
   - Use the iteration information to pace your work effectively.

4. Tool Usage:
   - Leverage all available tools to accomplish your goals efficiently.
   - Prefer edit_and_apply for file modifications, applying changes in chunks for large edits.
   - Use tavily_search proactively for up-to-date information.

5. Error Handling:
   - If a tool operation fails, analyze the error and attempt to resolve the issue.
   - For persistent errors, consider alternative approaches to achieve the goal.

6. Automode Completion:
   - When all goals are completed, respond with "AUTOMODE_COMPLETE" to exit automode.
   - Do not ask for additional tasks or modifications once goals are achieved.

7. Iteration Awareness:
   - You have access to this {iteration_info}.
   - Use this information to prioritize tasks and manage time effectively.

Remember: Focus on completing the established goals efficiently and effectively. Avoid unnecessary conversations or requests for additional tasks.
"""


def update_system_prompt(current_iteration: Optional[int] = None, max_iterations: Optional[int] = None) -> str:
    global file_contents
    chain_of_thought_prompt = """
    Answer the user's request using relevant tools (if they are available). Before calling a tool, do some analysis within <thinking></thinking> tags. First, think about which of the provided tools is the relevant tool to answer the user's request. Second, go through each of the required parameters of the relevant tool and determine if the user has directly provided or given enough information to infer a value. When deciding if the parameter can be inferred, carefully consider all the context to see if it supports a specific value. If all of the required parameters are present or can be reasonably inferred, close the thinking tag and proceed with the tool call. BUT, if one of the values for a required parameter is missing, DO NOT invoke the function (not even with fillers for the missing params) and instead, ask the user to provide the missing parameters. DO NOT ask for more information on optional parameters if it is not provided.

    Do not reflect on the quality of the returned search results in your response.
    """
    
    file_contents_prompt = "\n\nFile Contents:\n"
    for path, content in file_contents.items():
        file_contents_prompt += f"\n--- {path} ---\n{content}\n"
    
    if automode:
        iteration_info = ""
        if current_iteration is not None and max_iterations is not None:
            iteration_info = f"You are currently on iteration {current_iteration} out of {max_iterations} in automode."
        return BASE_SYSTEM_PROMPT + file_contents_prompt + "\n\n" + AUTOMODE_SYSTEM_PROMPT.format(iteration_info=iteration_info) + "\n\n" + chain_of_thought_prompt
    else:
        return BASE_SYSTEM_PROMPT + file_contents_prompt + "\n\n" + chain_of_thought_prompt

def create_folder(path):
    try:
        os.makedirs(path, exist_ok=True)
        return f"Folder created: {path}"
    except Exception as e:
        return f"Error creating folder: {str(e)}"

def create_file(path, content=""):
    global file_contents
    try:
        with open(path, 'w') as f:
            f.write(content)
        file_contents[path] = content
        return f"File created and added to system prompt: {path}"
    except Exception as e:
        return f"Error creating file: {str(e)}"

def highlight_diff(diff_text):
    return Syntax(diff_text, "diff", theme="monokai", line_numbers=True)

def generate_and_apply_diff(original_content, new_content, path):
    diff = list(difflib.unified_diff(
        original_content.splitlines(keepends=True),
        new_content.splitlines(keepends=True),
        fromfile=f"a/{path}",
        tofile=f"b/{path}",
        n=3
    ))

    if not diff:
        return "No changes detected."

    try:
        with open(path, 'w') as f:
            f.writelines(new_content)

        diff_text = ''.join(diff)
        highlighted_diff = highlight_diff(diff_text)

        diff_panel = Panel(
            highlighted_diff,
            title=f"Changes in {path}",
            expand=False,
            border_style="cyan"
        )

        console.print(diff_panel)

        added_lines = sum(1 for line in diff if line.startswith('+') and not line.startswith('+++'))
        removed_lines = sum(1 for line in diff if line.startswith('-') and not line.startswith('---'))

        summary = f"Changes applied to {path}:\n"
        summary += f"  Lines added: {added_lines}\n"
        summary += f"  Lines removed: {removed_lines}\n"

        return summary

    except Exception as e:
        error_panel = Panel(
            f"Error: {str(e)}",
            title="Error Applying Changes",
            style="bold red"
        )
        console.print(error_panel)
        return f"Error applying changes: {str(e)}"


async def generate_edit_instructions(file_path, file_content, instructions, project_context, full_file_contents):
    global code_editor_tokens, code_editor_memory, code_editor_files
    try:
        # Prepare memory context (this is the only part that maintains some context between calls)
        memory_context = "\n".join([f"Memory {i+1}:\n{mem}" for i, mem in enumerate(code_editor_memory)])

        # Prepare full file contents context, excluding the file being edited if it's already in code_editor_files
        full_file_contents_context = "\n\n".join([
            f"--- {path} ---\n{content}" for path, content in full_file_contents.items()
            if path != file_path or path not in code_editor_files
        ])

        system_prompt = f"""
        You are an AI coding agent that generates edit instructions for code files. Your task is to analyze the provided code and generate SEARCH/REPLACE blocks for necessary changes. Follow these steps:

        1. Review the entire file content to understand the context:
        {file_content}

        2. Carefully analyze the specific instructions:
        {instructions}

        3. Take into account the overall project context:
        {project_context}

        4. Consider the memory of previous edits:
        {memory_context}

        5. Consider the full context of all files in the project:
        {full_file_contents_context}

        6. Generate SEARCH/REPLACE blocks for each necessary change. Each block should:
           - Include enough context to uniquely identify the code to be changed
           - Provide the exact replacement code, maintaining correct indentation and formatting
           - Focus on specific, targeted changes rather than large, sweeping modifications

        7. Ensure that your SEARCH/REPLACE blocks:
           - Address all relevant aspects of the instructions
           - Maintain or enhance code readability and efficiency
           - Consider the overall structure and purpose of the code
           - Follow best practices and coding standards for the language
           - Maintain consistency with the project context and previous edits
           - Take into account the full context of all files in the project

        IMPORTANT: RETURN ONLY THE SEARCH/REPLACE BLOCKS. NO EXPLANATIONS OR COMMENTS.
        USE THE FOLLOWING FORMAT FOR EACH BLOCK:

        <SEARCH>
        Code to be replaced
        </SEARCH>
        <REPLACE>
        New code to insert
        </REPLACE>

        If no changes are needed, return an empty list.
        """

        # Make the API call to CODEEDITORMODEL (context is not maintained except for code_editor_memory)
        response = client.messages.create(
            model=CODEEDITORMODEL,
            max_tokens=8000,
            system=system_prompt,
            extra_headers={"anthropic-beta": "max-tokens-3-5-sonnet-2024-07-15"},
            messages=[
                {"role": "user", "content": "Generate SEARCH/REPLACE blocks for the necessary changes."}
            ]
        )
        # Update token usage for code editor
        code_editor_tokens['input'] += response.usage.input_tokens
        code_editor_tokens['output'] += response.usage.output_tokens

        # Parse the response to extract SEARCH/REPLACE blocks
        edit_instructions = parse_search_replace_blocks(response.content[0].text)

        # Update code editor memory (this is the only part that maintains some context between calls)
        code_editor_memory.append(f"Edit Instructions for {file_path}:\n{response.content[0].text}")

        # Add the file to code_editor_files set
        code_editor_files.add(file_path)

        return edit_instructions

    except Exception as e:
        console.print(f"Error in generating edit instructions: {str(e)}", style="bold red")
        return []  # Return empty list if any exception occurs



def parse_search_replace_blocks(response_text):
    blocks = []
    pattern = r'<SEARCH>\n(.*?)\n</SEARCH>\n<REPLACE>\n(.*?)\n</REPLACE>'
    matches = re.findall(pattern, response_text, re.DOTALL)
    
    for search, replace in matches:
        blocks.append({
            'search': search.strip(),
            'replace': replace.strip()
        })
    
    return json.dumps(blocks)  # Keep returning JSON string


async def edit_and_apply(path, instructions, project_context, is_automode=False, max_retries=3):
    global file_contents
    try:
        original_content = file_contents.get(path, "")
        if not original_content:
            with open(path, 'r') as file:
                original_content = file.read()
            file_contents[path] = original_content

        for attempt in range(max_retries):
            edit_instructions_json = await generate_edit_instructions(path, original_content, instructions, project_context, file_contents)
            
            if edit_instructions_json:
                edit_instructions = json.loads(edit_instructions_json)  # Parse JSON here
                console.print(Panel(f"Attempt {attempt + 1}/{max_retries}: The following SEARCH/REPLACE blocks have been generated:", title="Edit Instructions", style="cyan"))
                for i, block in enumerate(edit_instructions, 1):
                    console.print(f"Block {i}:")
                    console.print(Panel(f"SEARCH:\n{block['search']}\n\nREPLACE:\n{block['replace']}", expand=False))

                edited_content, changes_made, failed_edits = await apply_edits(path, edit_instructions, original_content)

                if changes_made:
                    file_contents[path] = edited_content  # Update the file_contents with the new content
                    console.print(Panel(f"File contents updated in system prompt: {path}", style="green"))
                    
                    if failed_edits:
                        console.print(Panel(f"Some edits could not be applied. Retrying...", style="yellow"))
                        instructions += f"\n\nPlease retry the following edits that could not be applied:\n{failed_edits}"
                        original_content = edited_content
                        continue
                    
                    return f"Changes applied to {path}"
                elif attempt == max_retries - 1:
                    return f"No changes could be applied to {path} after {max_retries} attempts. Please review the edit instructions and try again."
                else:
                    console.print(Panel(f"No changes could be applied in attempt {attempt + 1}. Retrying...", style="yellow"))
            else:
                return f"No changes suggested for {path}"
        
        return f"Failed to apply changes to {path} after {max_retries} attempts."
    except Exception as e:
        return f"Error editing/applying to file: {str(e)}"



async def apply_edits(file_path, edit_instructions, original_content):
    changes_made = False
    edited_content = original_content
    total_edits = len(edit_instructions)
    failed_edits = []

    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        console=console
    ) as progress:
        edit_task = progress.add_task("[cyan]Applying edits...", total=total_edits)

        for i, edit in enumerate(edit_instructions, 1):
            search_content = edit['search'].strip()
            replace_content = edit['replace'].strip()
            
            # Use regex to find the content, ignoring leading/trailing whitespace
            pattern = re.compile(re.escape(search_content), re.DOTALL)
            match = pattern.search(edited_content)
            
            if match:
                # Replace the content, preserving the original whitespace
                start, end = match.span()
                # Strip <SEARCH> and <REPLACE> tags from replace_content
                replace_content_cleaned = re.sub(r'</?SEARCH>|</?REPLACE>', '', replace_content)
                edited_content = edited_content[:start] + replace_content_cleaned + edited_content[end:]
                changes_made = True
                
                # Display the diff for this edit
                diff_result = generate_diff(search_content, replace_content, file_path)
                console.print(Panel(diff_result, title=f"Changes in {file_path} ({i}/{total_edits})", style="cyan"))
            else:
                console.print(Panel(f"Edit {i}/{total_edits} not applied: content not found", style="yellow"))
                failed_edits.append(f"Edit {i}: {search_content}")

            progress.update(edit_task, advance=1)

    if not changes_made:
        console.print(Panel("No changes were applied. The file content already matches the desired state.", style="green"))
    else:
        # Write the changes to the file
        with open(file_path, 'w') as file:
            file.write(edited_content)
        console.print(Panel(f"Changes have been written to {file_path}", style="green"))

    return edited_content, changes_made, "\n".join(failed_edits)

def generate_diff(original, new, path):
    diff = list(difflib.unified_diff(
        original.splitlines(keepends=True),
        new.splitlines(keepends=True),
        fromfile=f"a/{path}",
        tofile=f"b/{path}",
        n=3
    ))

    diff_text = ''.join(diff)
    highlighted_diff = highlight_diff(diff_text)

    return highlighted_diff

def read_file(path):
    global file_contents
    try:
        with open(path, 'r') as f:
            content = f.read()
        file_contents[path] = content
        return f"File '{path}' has been read and stored in the system prompt."
    except Exception as e:
        return f"Error reading file: {str(e)}"

def read_multiple_files(paths):
    global file_contents
    results = []
    for path in paths:
        try:
            with open(path, 'r') as f:
                content = f.read()
            file_contents[path] = content
            results.append(f"File '{path}' has been read and stored in the system prompt.")
        except Exception as e:
            results.append(f"Error reading file '{path}': {str(e)}")
    return "\n".join(results)

def list_files(path="."):
    try:
        files = os.listdir(path)
        return "\n".join(files)
    except Exception as e:
        return f"Error listing files: {str(e)}"

def tavily_search(query):
    try:
        response = tavily.qna_search(query=query, search_depth="advanced")
        return response
    except Exception as e:
        return f"Error performing search: {str(e)}"

tools = [
    {
        "type": "function",
        "function": {
            "name": "create_folder",
            "description": "Create a new folder at the specified path",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "The absolute or relative path where the folder should be created"
                    }
                },
                "required": ["path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "create_file",
            "description": "Create a new file at the specified path with the given content",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "The absolute or relative path where the file should be created"
                    },
                    "content": {
                        "type": "string",
                        "description": "The content of the file"
                    }
                },
                "required": ["path", "content"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "edit_and_apply",
            "description": "Apply AI-powered improvements to a file based on specific instructions and project context",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "The absolute or relative path of the file to edit"
                    },
                    "instructions": {
                        "type": "string",
                        "description": "Detailed instructions for the changes to be made"
                    },
                    "project_context": {
                        "type": "string",
                        "description": "Comprehensive context about the project"
                    }
                },
                "required": ["path", "instructions", "project_context"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": "Read the contents of a file at the specified path",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "The absolute or relative path of the file to read"
                    }
                },
                "required": ["path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "read_multiple_files",
            "description": "Read the contents of multiple files at the specified paths",
            "parameters": {
                "type": "object",
                "properties": {
                    "paths": {
                        "type": "array",
                        "items": {
                            "type": "string"
                        },
                        "description": "An array of absolute or relative paths of the files to read"
                    }
                },
                "required": ["paths"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "list_files",
            "description": "List all files and directories in the specified folder",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "The absolute or relative path of the folder to list"
                    }
                }
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "tavily_search",
            "description": "Perform a web search using the Tavily API",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The search query"
                    }
                },
                "required": ["query"]
            }
        }
    }
]

from typing import Dict, Any

async def execute_tool(tool_call: Dict[str, Any]) -> Dict[str, Any]:
    try:
        function_call = tool_call['function']
        tool_name = function_call['name']
        tool_arguments = function_call['arguments']
        
        # Check if tool_arguments is a string and parse it if necessary
        if isinstance(tool_arguments, str):
            try:
                tool_input = json.loads(tool_arguments)
            except json.JSONDecodeError:
                return {
                    "content": f"Error: Failed to parse tool arguments for {tool_name}",
                    "is_error": True
                }
        else:
            tool_input = tool_arguments

        result = None
        is_error = False

        if tool_name == "create_folder":
            if "path" not in tool_input:
                raise KeyError("Missing 'path' parameter for create_folder")
            result = create_folder(tool_input["path"])
        elif tool_name == "create_file":
            result = create_file(tool_input["path"], tool_input.get("content", ""))
        elif tool_name == "edit_and_apply":
            result = await edit_and_apply(
                tool_input["path"],
                tool_input["instructions"],
                tool_input["project_context"],
                is_automode=automode
            )
        elif tool_name == "read_file":
            result = read_file(tool_input["path"])
        elif tool_name == "read_multiple_files":
            result = read_multiple_files(tool_input["paths"])
        elif tool_name == "list_files":
            result = list_files(tool_input.get("path", "."))
        elif tool_name == "tavily_search":
            result = tavily_search(tool_input["query"])
        else:
            is_error = True
            result = f"Unknown tool: {tool_name}"

        return {
            "content": result,
            "is_error": is_error
        }
    except KeyError as e:
        error_message = f"Missing required parameter {str(e)} for tool {tool_name}"
        logging.error(error_message)
        return {
            "content": f"Error: {error_message}",
            "is_error": True
        }
    except Exception as e:
        error_message = f"Error executing tool {tool_name}: {str(e)}"
        logging.error(error_message)
        return {
            "content": f"Error: {error_message}",
            "is_error": True
        }


def parse_goals(response):
    goals = re.findall(r'Goal \d+: (.+)', response)
    return goals

async def execute_goals(goals):
    global automode
    for i, goal in enumerate(goals, 1):
        console.print(Panel(f"Executing Goal {i}: {goal}", title="Goal Execution", style="bold yellow"))
        response, _ = await chat_with_ollama(f"Continue working on goal: {goal}")
        if CONTINUATION_EXIT_PHRASE in response:
            automode = False
            console.print(Panel("Exiting automode.", title="Automode", style="bold green"))
            break

async def run_goals(response):
    goals = parse_goals(response)
    await execute_goals(goals)


def save_chat():
    # Generate filename
    now = datetime.datetime.now()
    filename = f"Chat_{now.strftime('%H%M')}.md"
    
    # Format conversation history
    formatted_chat = "# Claude-3-Sonnet Engineer Chat Log\n\n"
    for message in conversation_history:
        if message['role'] == 'user':
            formatted_chat += f"## User\n\n{message['content']}\n\n"
        elif message['role'] == 'assistant':
            if isinstance(message['content'], str):
                formatted_chat += f"## Claude\n\n{message['content']}\n\n"
            elif isinstance(message['content'], list):
                for content in message['content']:
                    if content['type'] == 'tool_use':
                        formatted_chat += f"### Tool Use: {content['name']}\n\n```json\n{json.dumps(content['input'], indent=2)}\n```\n\n"
                    elif content['type'] == 'text':
                        formatted_chat += f"## Claude\n\n{content['text']}\n\n"
        elif message['role'] == 'user' and isinstance(message['content'], list):
            for content in message['content']:
                if content['type'] == 'tool_result':
                    formatted_chat += f"### Tool Result\n\n```\n{content['content']}\n```\n\n"
    
    # Save to file
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(formatted_chat)
    
    return filename



async def chat_with_ollama(user_input, image_path=None, current_iteration=None, max_iterations=None):
    global conversation_history, automode, main_model_tokens

    # This function uses MAINMODEL, which maintains context across calls
    current_conversation = []

    current_conversation.append({"role": "user", "content": user_input})

    # Filter conversation history to maintain context
    filtered_conversation_history = []
    for message in conversation_history:
        if isinstance(message['content'], list):
            filtered_content = [
                content for content in message['content']
                if content.get('type') != 'tool_result' or (
                    content.get('type') == 'tool_result' and
                    not any(keyword in content.get('output', '') for keyword in [
                        "File contents updated in system prompt",
                        "File created and added to system prompt",
                        "has been read and stored in the system prompt"
                    ])
                )
            ]
            if filtered_content:
                filtered_conversation_history.append({**message, 'content': filtered_content})
        else:
            filtered_conversation_history.append(message)

    # Combine filtered history with current conversation to maintain context
    messages = filtered_conversation_history + current_conversation

    try:
        # MAINMODEL call, which maintains context
        # Prepend the system message to the messages list
        system_message = {"role": "system", "content": update_system_prompt(current_iteration, max_iterations)}
        messages_with_system = [system_message] + messages
        
        response = await client.chat(
            model=MAINMODEL,
            messages=messages_with_system,
            tools=tools,
            stream=False
        )
        
        # Check if the response is a dictionary
        if isinstance(response, dict):
            if 'error' in response:
                console.print(Panel(f"Error: {response['error']}", title="API Error", style="bold red"))
                return f"I'm sorry, but there was an error with the model response: {response['error']}", False
            elif 'message' in response:
                assistant_message = response['message']
                assistant_response = assistant_message.get('content', '')
                exit_continuation = CONTINUATION_EXIT_PHRASE in assistant_response
                tool_calls = assistant_message.get('tool_calls', [])
            else:
                # Handle unexpected dictionary response
                console.print(Panel("Unexpected response format", title="API Error", style="bold red"))
                return "I'm sorry, but there was an unexpected error in the model response.", False
        else:
            # Handle unexpected non-dictionary response
            console.print(Panel("Unexpected response type", title="API Error", style="bold red"))
            return "I'm sorry, but there was an unexpected error in the model response.", False
    except Exception as e:
        console.print(Panel(f"API Error: {str(e)}", title="API Error", style="bold red"))
        return "I'm sorry, there was an error communicating with the AI. Please try again.", False

    console.print(Panel(Markdown(assistant_response), title="Ollama's Response", title_align="left", border_style="blue", expand=False))

    if tool_calls:
        console.print(Panel("Tool calls detected", title="Tool Usage", style="bold yellow"))
        console.print(Panel(json.dumps(tool_calls, indent=2), title="Tool Calls", style="cyan"))

    # Display files in context
    if file_contents:
        files_in_context = "\n".join(file_contents.keys())
    else:
        files_in_context = "No files in context. Read, create, or edit files to add."
    console.print(Panel(files_in_context, title="Files in Context", title_align="left", border_style="white", expand=False))

    for tool_call in tool_calls:
        tool_name = tool_call['function']['name']
        tool_arguments = tool_call['function']['arguments']
        
        # Check if tool_arguments is a string and parse it if necessary
        if isinstance(tool_arguments, str):
            try:
                tool_input = json.loads(tool_arguments)
            except json.JSONDecodeError:
                tool_input = {"error": "Failed to parse tool arguments"}
        else:
            tool_input = tool_arguments

        console.print(Panel(f"Tool Used: {tool_name}", style="green"))
        console.print(Panel(f"Tool Input: {json.dumps(tool_input, indent=2)}", style="green"))

        tool_result = await execute_tool(tool_call)
        
        if tool_result["is_error"]:
            console.print(Panel(tool_result["content"], title="Tool Execution Error", style="bold red"))
        else:
            console.print(Panel(tool_result["content"], title_align="left", title="Tool Result", style="green"))

        current_conversation.append({
            "role": "assistant",
            "content": None,
            "tool_calls": [tool_call]
        })

        current_conversation.append({
            "role": "tool",
            "content": tool_result["content"],
            "tool_call_id": tool_call.get('id', 'unknown_id')  # Use 'unknown_id' if 'id' is not present
        })

        # Update the file_contents dictionary if applicable
        if tool_name in ['create_file', 'edit_and_apply', 'read_file'] and not tool_result["is_error"]:
            if 'path' in tool_input:
                file_path = tool_input['path']
                if "File contents updated in system prompt" in tool_result["content"] or \
                   "File created and added to system prompt" in tool_result["content"] or \
                   "has been read and stored in the system prompt" in tool_result["content"]:
                    # The file_contents dictionary is already updated in the tool function
                    pass

        messages = filtered_conversation_history + current_conversation

        try:
            # Prepend the system message to the messages list
            system_message = {"role": "system", "content": update_system_prompt(current_iteration, max_iterations)}
            messages_with_system = [system_message] + messages
            
            tool_response = await client.chat(
                model=TOOLCHECKERMODEL,
                messages=messages_with_system,
                tools=tools,
                stream=False
            )

            if isinstance(tool_response, dict) and 'message' in tool_response:
                tool_checker_response = tool_response['message'].get('content', '')
                console.print(Panel(Markdown(tool_checker_response), title="Ollama's Response to Tool Result",  title_align="left", border_style="blue", expand=False))
                assistant_response += "\n\n" + tool_checker_response
            else:
                error_message = "Unexpected tool response format"
                console.print(Panel(error_message, title="Error", style="bold red"))
                assistant_response += f"\n\n{error_message}"
        except Exception as e:
            error_message = f"Error in tool response: {str(e)}"
            console.print(Panel(error_message, title="Error", style="bold red"))
            assistant_response += f"\n\n{error_message}"

    if assistant_response:
        current_conversation.append({"role": "assistant", "content": assistant_response})

    conversation_history = messages + [{"role": "assistant", "content": assistant_response}]

    return assistant_response, exit_continuation

def reset_code_editor_memory():
    global code_editor_memory
    code_editor_memory = []
    console.print(Panel("Code editor memory has been reset.", title="Reset", style="bold green"))


def reset_conversation():
    global conversation_history, file_contents, code_editor_files
    conversation_history = []
    file_contents = {}
    code_editor_files = set()
    reset_code_editor_memory()
    console.print(Panel("Conversation history, file contents, code editor memory, and code editor files have been reset.", title="Reset", style="bold green"))




async def main():
    global automode, conversation_history
    console.print(Panel("Welcome to the Ollama Llama 3.1 Engineer Chat with Multi-Agent and Image Support!", title="Welcome", style="bold green"))
    console.print("Type 'exit' to end the conversation.")
    console.print("Type 'automode [number]' to enter Autonomous mode with a specific number of iterations.")
    console.print("Type 'reset' to clear the conversation history.")
    console.print("Type 'save chat' to save the conversation to a Markdown file.")
    console.print("While in automode, press Ctrl+C at any time to exit the automode to return to regular chat.")

    while True:
        user_input = await get_user_input()

        if user_input.lower() == 'exit':
            console.print(Panel("Thank you for chatting. Goodbye!", title_align="left", title="Goodbye", style="bold green"))
            break

        if user_input.lower() == 'reset':
            reset_conversation()
            continue

        if user_input.lower() == 'save chat':
            filename = save_chat()
            console.print(Panel(f"Chat saved to {filename}", title="Chat Saved", style="bold green"))
            continue


        if user_input.lower().startswith('automode'):
            try:
                parts = user_input.split()
                if len(parts) > 1 and parts[1].isdigit():
                    max_iterations = int(parts[1])
                else:
                    max_iterations = MAX_CONTINUATION_ITERATIONS

                automode = True
                console.print(Panel(f"Entering automode with {max_iterations} iterations. Please provide the goal of the automode.", title_align="left", title="Automode", style="bold yellow"))
                console.print(Panel("Press Ctrl+C at any time to exit the automode loop.", style="bold yellow"))
                user_input = await get_user_input()

                iteration_count = 0
                try:
                    while automode and iteration_count < max_iterations:
                        response, exit_continuation = await chat_with_ollama(user_input, current_iteration=iteration_count+1, max_iterations=max_iterations)

                        if exit_continuation or CONTINUATION_EXIT_PHRASE in response:
                            console.print(Panel("Automode completed.", title_align="left", title="Automode", style="green"))
                            automode = False
                        else:
                            console.print(Panel(f"Continuation iteration {iteration_count + 1} completed. Press Ctrl+C to exit automode. ", title_align="left", title="Automode", style="yellow"))
                            user_input = "Continue with the next step. Or STOP by saying 'AUTOMODE_COMPLETE' if you think you've achieved the results established in the original request."
                        iteration_count += 1

                        if iteration_count >= max_iterations:
                            console.print(Panel("Max iterations reached. Exiting automode.", title_align="left", title="Automode", style="bold red"))
                            automode = False
                except KeyboardInterrupt:
                    console.print(Panel("\nAutomode interrupted by user. Exiting automode.", title_align="left", title="Automode", style="bold red"))
                    automode = False
                    if conversation_history and conversation_history[-1]["role"] == "user":
                        conversation_history.append({"role": "assistant", "content": "Automode interrupted. How can I assist you further?"})
            except KeyboardInterrupt:
                console.print(Panel("\nAutomode interrupted by user. Exiting automode.", title_align="left", title="Automode", style="bold red"))
                automode = False
                if conversation_history and conversation_history[-1]["role"] == "user":
                    conversation_history.append({"role": "assistant", "content": "Automode interrupted. How can I assist you further?"})

            console.print(Panel("Exited automode. Returning to regular chat.", style="green"))
        else:
            response, _ = await chat_with_ollama(user_input)

if __name__ == "__main__":
    asyncio.run(main())



================================================
FILE: Claude-Eng-v2/requirements.txt
================================================
anthropic
python-dotenv
tavily-python
Pillow
anthropic
rich
prompt_toolkit
pydub
websockets
SpeechRecognition



================================================
FILE: prompts/system_prompts.py
================================================
class SystemPrompts:
    TOOL_USAGE = """
    When using tools, please follow these guidelines:
    1. Think carefully about which tool is appropriate for the task
    2. Only use tools when necessary
    3. Ask for clarification if required parameters are missing
    4. Explain your choices and results in a natural way
    5. Available tools and their use cases
    6. Chain multiple tools together to achieve complex goals:
       - Break down the goal into logical steps
       - Use tools sequentially to complete each step
       - Pass outputs from one tool as inputs to the next
       - Continue running tools until the full goal is achieved
       - Provide clear updates on progress through the chain
    7. Available tools and their use cases
       - BrowserTool: Opens URLs in system's default browser
       - CreateFoldersTool: Creates new folders and nested directories
       - DiffEditorTool: Performs precise text replacements in files
       - DuckDuckGoTool: Performs web searches using DuckDuckGo
       - Explorer: Enhanced file/directory management (list, create, delete, move, search)
       - FileContentReaderTool: Reads content from multiple files\
       - FileCreatorTool: Creates new files with specified content
       - FileEditTool: Edits existing file contents
       - GitOperationsTool: Handles Git operations (clone, commit, push, etc.)
       - LintingTool: Lints Python code using Ruff
       - SequentialThinkingTool: Helps break down complex problems into steps
       - ShellTool: Executes shell commands securely
       - ToolCreatorTool: Creates new tool classes based on descriptions
       - UVPackageManager: Manages Python packages using UV
       - WebScraperTool: Extracts content from web pages

    6. Consider creating new tools only when:
       - The requested capability is completely outside existing tools
       - The functionality can't be achieved by combining existing tools
       - The new tool would serve a distinct and reusable purpose
       Do not create new tools if:
       - An existing tool can handle the task, even partially
       - The functionality is too similar to existing tools
       - The tool would be too specific or single-use
    """

    DEFAULT = """
    I am Claude Engineer v3, a powerful AI assistant specialized in software development.
    I have access to various tools for file management, code execution, web interactions,
    and development workflows.

    My capabilities include:
    1. File Operations:
       - Creating/editing files and folders
       - Reading file contents
       - Managing file systems
    
    2. Development Tools:
       - Package management with UV
    
    3. Web Interactions:
       - Web scraping
       - DuckDuckGo searches
       - URL handling
    
    4. Problem Solving:
       - Sequential thinking for complex problems
       - Tool creation for new capabilities
       - Secure command execution
    
    I will:
    - Think through problems carefully
    - Show my reasoning clearly
    - Ask for clarification when needed
    - Use the most appropriate tools for each task
    - Explain my choices and results
    - Handle errors gracefully
    
    I can help with various development tasks while maintaining
    security and following best practices.
    """



================================================
FILE: static/css/style.css
================================================
/* Custom scrollbar */
::-webkit-scrollbar {
    width: 8px;
}
::-webkit-scrollbar-track {
    background: transparent;
}
::-webkit-scrollbar-thumb {
    background: #cbd5e1;
    border-radius: 4px;
}
::-webkit-scrollbar-thumb:hover {
    background: #94a3b8;
}

/* Code block styling */
pre {
    background: #f8fafc;
    border-radius: 6px;
    padding: 1rem;
    margin: 0.5rem 0;
    overflow-x: auto;
}
code {
    font-family: ui-monospace, monospace;
    font-size: 0.9em;
}

/* Chat container styles */
.chat-container {
    display: flex;
    flex-direction: column;
    height: 100vh;
    overflow: hidden;
}

.messages-container {
    flex: 1;
    overflow-y: auto;
    padding: 1rem;
    padding-bottom: 2rem;
    max-width: 5xl;
    margin: 0 auto;
    width: 100%;
}

.input-container {
    position: sticky;
    bottom: 0;
    background-color: white;
    border-top: 1px solid #e5e7eb;
    padding: 1rem 0;
    width: 100%;
    box-shadow: 0 -4px 6px -1px rgb(0 0 0 / 0.05);
}

@keyframes pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.5; }
}

.thinking {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    color: #6b7280;
    font-size: 0.875rem;
}

.thinking::before {
    content: '';
    width: 0.5rem;
    height: 0.5rem;
    background-color: currentColor;
    border-radius: 50%;
    animation: pulse 1.5s ease-in-out infinite;
}

.thinking-dots span {
    animation: pulse 1.5s ease-in-out infinite;
    display: inline-block;
    margin-right: 2px;
}

.thinking-dots span:nth-child(2) {
    animation-delay: 0.2s;
}

.thinking-dots span:nth-child(3) {
    animation-delay: 0.4s;
}

/* Update the messages spacing */
.message-wrapper {
    margin: 0 auto 1.5rem;
    max-width: 5xl;
    padding: 0 1rem;
}

.message-wrapper:last-child {
    margin-bottom: 2rem;
}

/* Special spacing for consecutive messages */
.message-wrapper + .message-wrapper {
    margin-top: 1.5rem;
}

/* Update the primary color to Tailwind black */
.ai-avatar {
    background-color: #111827; /* Tailwind black-900 */
}

/* Add to your existing CSS */
.tool-usage {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    color: #6b7280;
    font-size: 0.875rem;
    padding: 0.5rem 0.75rem;
    background-color: #f8fafc;
    border-radius: 0.5rem;
}

.tool-usage::before {
    content: 'ğŸ”§';
    font-size: 1rem;
}

/* Add responsive container styles */
@media (max-width: 640px) {
    .input-container {
        padding: 0.75rem 0;
    }
    
    .messages-container {
        padding: 0.75rem;
    }
}

/* Add these styles to your existing CSS */
.token-usage-container {
    position: sticky;
    bottom: 80px;
    background-color: white;
    padding: 0.5rem 0;
    border-top: 1px solid #e5e7eb;
    z-index: 10;
}

.token-bar-container {
    flex: 1;
    height: 8px;
    background-color: #f3f4f6;
    border-radius: 4px;
    overflow: hidden;
}

.token-bar {
    height: 100%;
    background-color: #10b981; /* Green by default */
    border-radius: 4px;
    transition: width 0.3s ease, background-color 0.3s ease;
}

.token-bar.warning {
    background-color: #f59e0b; /* Yellow for warning */
}

.token-bar.danger {
    background-color: #ef4444; /* Red for danger */
}

.token-count {
    min-width: 160px;
}

.token-percentage {
    min-width: 48px;
    text-align: right;
}

/* Add these styles to your existing CSS */
.message-wrapper .prose p {
    color: #18181B;
    font-size: 14px;
    line-height: 1.5;
}

/* For user messages */
.message-wrapper .prose {
    color: #18181B;
    font-size: 14px;
    line-height: 1.5;
}

.command-code {
    background-color: #e7f3ed;
    color: #0a3622;
    padding: 2px 6px;
    border-radius: 4px;
    font-family: monospace;
}
  


================================================
FILE: static/js/chat.js
================================================
let currentImageData = null;
let currentMediaType = null;

// Auto-resize textarea
const textarea = document.getElementById('message-input');
textarea.addEventListener('input', function() {
    this.style.height = '28px';
    this.style.height = (this.scrollHeight) + 'px';
});

function appendMessage(content, isUser = false) {
    const messagesDiv = document.getElementById('chat-messages');
    const messageWrapper = document.createElement('div');
    messageWrapper.className = 'message-wrapper';
    
    const messageDiv = document.createElement('div');
    messageDiv.className = 'flex items-start space-x-4 space-y-1';
    
    // Avatar
    const avatarDiv = document.createElement('div');
    if (isUser) {
        avatarDiv.className = 'w-8 h-8 rounded-full bg-gray-200 flex items-center justify-center text-gray-600 font-bold text-xs';
        avatarDiv.textContent = 'You';
    } else {
        avatarDiv.className = 'w-8 h-8 rounded-full ai-avatar flex items-center justify-center text-white font-bold text-xs';
        avatarDiv.textContent = 'CE';
    }
    
    // Message content
    const contentDiv = document.createElement('div');
    contentDiv.className = 'flex-1';
    
    const innerDiv = document.createElement('div');
    innerDiv.className = 'prose prose-slate max-w-none';
    
    if (!isUser && content) {
        try {
            innerDiv.innerHTML = marked.parse(content);
        } catch (e) {
            console.error('Error parsing markdown:', e);
            innerDiv.textContent = content;
        }
    } else {
        innerDiv.textContent = content || '';
    }
    
    contentDiv.appendChild(innerDiv);
    messageDiv.appendChild(avatarDiv);
    messageDiv.appendChild(contentDiv);
    messageWrapper.appendChild(messageDiv);
    messagesDiv.appendChild(messageWrapper);
    messagesDiv.scrollTop = messagesDiv.scrollHeight;
}

// Event Listeners
document.getElementById('upload-btn').addEventListener('click', () => {
    document.getElementById('file-input').click();
});

document.getElementById('file-input').addEventListener('change', async (e) => {
    const file = e.target.files[0];
    if (file) {
        const formData = new FormData();
        formData.append('file', file);

        try {
            const response = await fetch('/upload', {
                method: 'POST',
                body: formData
            });
            const data = await response.json();
            
            if (data.success) {
                currentImageData = data.image_data;
                currentMediaType = data.media_type;
                document.getElementById('preview-img').src = `data:${data.media_type};base64,${data.image_data}`;
                document.getElementById('image-preview').classList.remove('hidden');
            }
        } catch (error) {
            console.error('Error uploading image:', error);
        }
    }
});

document.getElementById('remove-image').addEventListener('click', () => {
    currentImageData = null;
    document.getElementById('image-preview').classList.add('hidden');
    document.getElementById('file-input').value = '';
});

function appendThinkingIndicator() {
    const messagesDiv = document.getElementById('chat-messages');
    const messageWrapper = document.createElement('div');
    messageWrapper.className = 'message-wrapper thinking-message';
    
    const messageDiv = document.createElement('div');
    messageDiv.className = 'flex items-start space-x-4';
    
    // AI Avatar
    const avatarDiv = document.createElement('div');
    avatarDiv.className = 'w-8 h-8 rounded-full ai-avatar flex items-center justify-center text-white font-bold text-sm';
    avatarDiv.textContent = 'CE';
    
    // Thinking content
    const contentDiv = document.createElement('div');
    contentDiv.className = 'flex-1';
    
    const thinkingDiv = document.createElement('div');
    thinkingDiv.className = 'thinking';
    thinkingDiv.innerHTML = '<div style="margin-top: 6px; margin-bottom: 4px;">Thinking<span class="thinking-dots"><span>.</span><span>.</span><span>.</span></span></div>';
    
    contentDiv.appendChild(thinkingDiv);
    messageDiv.appendChild(avatarDiv);
    messageDiv.appendChild(contentDiv);
    messageWrapper.appendChild(messageDiv);
    messagesDiv.appendChild(messageWrapper);
    messagesDiv.scrollTop = messagesDiv.scrollHeight;
    
    return messageWrapper;
}

// Add command+enter handler
document.getElementById('message-input').addEventListener('keydown', (e) => {
    if ((e.metaKey || e.ctrlKey) && e.key === 'Enter') {
        e.preventDefault();
        document.getElementById('chat-form').dispatchEvent(new Event('submit'));
    }
});

// Add function to show tool usage
function appendToolUsage(toolName) {
    const messagesDiv = document.getElementById('chat-messages');
    const messageWrapper = document.createElement('div');
    messageWrapper.className = 'message-wrapper';
    
    const messageDiv = document.createElement('div');
    messageDiv.className = 'flex items-start space-x-4';
    
    // AI Avatar
    const avatarDiv = document.createElement('div');
    avatarDiv.className = 'w-8 h-8 rounded-full ai-avatar flex items-center justify-center text-white font-bold text-sm';
    avatarDiv.textContent = 'CE';
    
    // Tool usage content
    const contentDiv = document.createElement('div');
    contentDiv.className = 'flex-1';
    
    const toolDiv = document.createElement('div');
    toolDiv.className = 'tool-usage';
    toolDiv.textContent = `Using tool: ${toolName}`;
    
    contentDiv.appendChild(toolDiv);
    messageDiv.appendChild(avatarDiv);
    messageDiv.appendChild(contentDiv);
    messageWrapper.appendChild(messageDiv);
    messagesDiv.appendChild(messageWrapper);
    messagesDiv.scrollTop = messagesDiv.scrollHeight;
}

// Add this function near the top of your file
function updateTokenUsage(usedTokens, maxTokens) {
    const percentage = (usedTokens / maxTokens) * 100;
    const tokenBar = document.getElementById('token-bar');
    const tokensUsed = document.getElementById('tokens-used');
    const tokenPercentage = document.getElementById('token-percentage');
    
    // Update the numbers
    tokensUsed.textContent = usedTokens.toLocaleString();
    tokenPercentage.textContent = `${percentage.toFixed(1)}%`;
    
    // Update the bar
    tokenBar.style.width = `${percentage}%`;
    
    // Update colors based on usage
    tokenBar.classList.remove('warning', 'danger');
    if (percentage > 90) {
        tokenBar.classList.add('danger');
    } else if (percentage > 75) {
        tokenBar.classList.add('warning');
    }
}

// Update the chat form submit handler
document.getElementById('chat-form').addEventListener('submit', async (e) => {
    e.preventDefault();
    
    const messageInput = document.getElementById('message-input');
    const message = messageInput.value.trim();
    
    if (!message && !currentImageData) return;
    
    // Append user message (and image if present)
    appendMessage(message, true);
    if (currentImageData) {
        // Optionally show the image in the chat
        const imagePreview = document.createElement('img');
        imagePreview.src = `data:image/jpeg;base64,${currentImageData}`;
        imagePreview.className = 'max-h-48 rounded-lg mt-2';
        document.querySelector('.message-wrapper:last-child .prose').appendChild(imagePreview);
    }
    
    // Clear input and reset height
    messageInput.value = '';
    resetTextarea();
    
    try {
        // Add thinking indicator
        const thinkingMessage = appendThinkingIndicator();
        
        const response = await fetch('/chat', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                message: message,
                image: currentImageData  // This will be null if no image is selected
            })
        });
        
        const data = await response.json();
        
        // Update token usage if provided in response
        if (data.token_usage) {
            updateTokenUsage(data.token_usage.total_tokens, data.token_usage.max_tokens);
        }
        
        // Remove thinking indicator
        if (thinkingMessage) {
            thinkingMessage.remove();
        }
        
        // Show tool usage if present
        if (data.tool_name) {
            appendToolUsage(data.tool_name);
        }
        
        // Show response if we have one
        if (data && data.response) {
            appendMessage(data.response);
        } else {
            appendMessage('Error: No response received');
        }
        
        // Clear image after sending
        currentImageData = null;
        document.getElementById('image-preview').classList.add('hidden');
        document.getElementById('file-input').value = '';
        
    } catch (error) {
        console.error('Error sending message:', error);
        document.querySelector('.thinking-message')?.remove();
        appendMessage('Error: Failed to send message');
    }
});

function resetTextarea() {
    const textarea = document.getElementById('message-input');
    textarea.style.height = '28px';
}

document.getElementById('chat-form').addEventListener('reset', () => {
    resetTextarea();
});

// Add at the top of the file
window.addEventListener('load', async () => {
    try {
        // Reset the conversation when page loads
        const response = await fetch('/reset', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            }
        });
        
        if (!response.ok) {
            console.error('Failed to reset conversation');
        }
        
        // Clear any existing messages except the first one
        const messagesDiv = document.getElementById('chat-messages');
        const messages = messagesDiv.getElementsByClassName('message-wrapper');
        while (messages.length > 1) {
            messages[1].remove();
        }
        
        // Reset any other state
        currentImageData = null;
        document.getElementById('image-preview')?.classList.add('hidden');
        document.getElementById('file-input').value = '';
        document.getElementById('message-input').value = '';
        resetTextarea();
        
        // Reset token usage display
        updateTokenUsage(0, 200000);
    } catch (error) {
        console.error('Error resetting conversation:', error);
    }
}); 


================================================
FILE: templates/index.html
================================================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Claude Engineer v3</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/marked@4.0.0/marked.min.js"></script>
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/github.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script>
        // Configure marked to use highlight.js
        marked.setOptions({
            highlight: function(code, lang) {
                if (lang && hljs.getLanguage(lang)) {
                    return hljs.highlight(code, { language: lang }).value;
                }
                return hljs.highlightAuto(code).value;
            }
        });
    </script>
</head>
<body class="bg-white">
    <div class="chat-container">
        <!-- Messages area -->
        <div class=" max-w-5xl mx-auto px-4 sm:px-6 lg:px-8 messages-container" id="chat-messages">
            <!-- Initial message -->
            <div class="message-wrapper initial-message">
                <div class="flex items-start space-x-4 space-y-1">
                    <div class="w-8 h-8 rounded-full ai-avatar flex items-center justify-center text-white font-bold text-xs">
                        CE
                    </div>
                    <div class="flex-1">
                        <div class="prose prose-slate max-w-none">
                            <p>Welcome to Claude Engineer v3! I'm here to help with programming and development tasks. I can create custom tools on demand to help with any task you need - just ask!</p>
                            
                            <p>Available commands:</p>
                            <p>
                                <span class="command-code">refresh</span> - Reload available tools<br>
                                <span class="command-code">reset</span> - Clear conversation history<br>
                                <span class="command-code">quit</span> - Exit the conversation
                            </p>
                            
                            
                            
                            <p>How can I assist you today?</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Add this right before the input-container div -->
        <div class="token-usage-container">
            <div class="max-w-3xl mx-auto px-4 sm:px-6 lg:px-8">
                <div class="flex items-center space-x-4 text-sm text-gray-500">
                    <div class="token-count">Total used: <span id="tokens-used">0</span> / <span id="max-tokens">200,000</span></div>
                    <div class="token-bar-container">
                        <div id="token-bar" class="token-bar" style="width: 0%"></div>
                    </div>
                    <div id="token-percentage" class="token-percentage">0%</div>
                </div>
            </div>
        </div>
        
        <!-- Fixed input area -->
        <div class="input-container">
            <div class="max-w-5xl mx-auto px-4 sm:px-6 lg:px-8">
                <form id="chat-form" class="relative">
                    <div id="image-preview" class="hidden mb-2">
                        <div class="relative inline-block">
                            <img id="preview-img" class="max-h-32 rounded-lg border border-gray-200" src="" alt="Preview">
                            <button type="button" id="remove-image" class="absolute -top-2 -right-2 bg-white rounded-full p-1 shadow-sm hover:bg-gray-100">
                                <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 text-gray-500" viewBox="0 0 20 20" fill="currentColor">
                                    <path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd" />
                                </svg>
                            </button>
                        </div>
                    </div>
                    <div class="flex items-end space-x-2 bg-white rounded-xl border border-gray-200 p-3 mx-2">
                        <button type="button" id="upload-btn" class="p-2 text-gray-400 hover:text-gray-600">
                            <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16l4.586-4.586a2 2 0 012.828 0L16 16m-2-2l1.586-1.586a2 2 0 012.828 0L20 14m-6-6h.01M6 20h12a2 2 0 002-2V6a2 2 0 00-2-2H6a2 2 0 00-2 2v12a2 2 0 002 2z" />
                            </svg>
                        </button>
                        <input type="file" id="file-input" class="hidden" accept="image/*">
                        <textarea id="message-input" 
                            class="flex-1 border-0 bg-transparent p-2 focus:ring-0 focus:outline-none resize-none max-h-32 overflow-y-auto min-h-[2.5rem]"
                            rows="1"
                            placeholder="Type something... (âŒ˜ + Enter to send)"
                            style="height: 40px; max-height: 200px;"
                        ></textarea>
                        <button type="submit" class="p-2 text-gray-400 hover:text-gray-600">
                            <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                                <path d="M10.894 2.553a1 1 0 00-1.788 0l-7 14a1 1 0 001.169 1.409l5-1.429A1 1 0 009 15.571V11a1 1 0 112 0v4.571a1 1 0 00.725.962l5 1.428a1 1 0 001.17-1.408l-7-14z" />
                            </svg>
                        </button>
                    </div>
                </form>
            </div>
        </div>
    </div>

    <script src="{{ url_for('static', filename='js/chat.js') }}"></script>
</body>
</html> 


================================================
FILE: tools/base.py
================================================
from abc import ABC, abstractmethod
from typing import Dict

class BaseTool(ABC):
    @property
    @abstractmethod
    def name(self) -> str:
        """Tool name that matches the regex ^[a-zA-Z0-9_-]{1,64}$"""
        pass

    @property
    @abstractmethod
    def description(self) -> str:
        """Detailed description of what the tool does"""
        pass

    @property
    @abstractmethod
    def input_schema(self) -> Dict:
        """JSON Schema defining the expected parameters"""
        pass

    @abstractmethod
    def execute(self, **kwargs) -> str:
        """Execute the tool with given parameters"""
        pass



================================================
FILE: tools/browsertool.py
================================================
from tools.base import BaseTool
import webbrowser
import validators
from typing import Union, List
from urllib.parse import urlparse

class BrowserTool(BaseTool):
    name = "browsertool"
    description = '''
    Opens URLs in the system's default web browser.
    Accepts a single URL or a list of URLs.
    Validates URL format and supports http/https protocols.
    Returns feedback on which URLs were successfully opened.
    '''
    input_schema = {
        "type": "object",
        "properties": {
            "urls": {
                "type": ["string", "array"],
                "items": {"type": "string"},
                "description": "Single URL or list of URLs to open"
            }
        },
        "required": ["urls"]
    }

    def _validate_url(self, url: str) -> bool:
        if not isinstance(url, str):
            return False
        if not validators.url(url):
            return False
        parsed = urlparse(url)
        return parsed.scheme in ['http', 'https']

    def execute(self, **kwargs) -> str:
        urls = kwargs.get('urls', [])
        if isinstance(urls, str):
            urls = [urls]

        results = []
        for url in urls:
            try:
                if not self._validate_url(url):
                    results.append(f"Failed to open {url}: Invalid URL format")
                    continue
                
                webbrowser.open(url)
                results.append(f"Successfully opened {url}")
            except Exception as e:
                results.append(f"Error opening {url}: {str(e)}")

        return "\n".join(results)


================================================
FILE: tools/createfolderstool.py
================================================
from tools.base import BaseTool
import os
import pathlib
from typing import List

class CreateFoldersTool(BaseTool):
    name = "createfolderstool"
    description = '''
    Creates new folders at specified paths, including nested directories if needed.
    Accepts a list of folder paths and creates each folder along with any necessary parent directories.
    Supports both absolute and relative paths.
    Returns status messages for each folder creation attempt.
    '''
    input_schema = {
        "type": "object",
        "properties": {
            "folder_paths": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "List of folder paths to create"
            }
        },
        "required": ["folder_paths"]
    }

    def execute(self, **kwargs) -> str:
        folder_paths: List[str] = kwargs.get("folder_paths", [])
        if not folder_paths:
            return "No folder paths provided"

        results = []
        for path in folder_paths:
            try:
                # Normalize path
                normalized_path = os.path.normpath(path)
                absolute_path = os.path.abspath(normalized_path)
                
                # Validate path
                if not all(c not in '<>:"|?*' for c in absolute_path):
                    results.append(f"Invalid characters in path: {path}")
                    continue

                # Create directory
                os.makedirs(absolute_path, exist_ok=True)
                results.append(f"Successfully created folder: {path}")

            except PermissionError:
                results.append(f"Permission denied: Unable to create folder {path}")
            except OSError as e:
                results.append(f"Error creating folder {path}: {str(e)}")
            except Exception as e:
                results.append(f"Unexpected error creating folder {path}: {str(e)}")

        return "\n".join(results)


================================================
FILE: tools/diffeditortool.py
================================================
from tools.base import BaseTool
import os
from typing import Dict

class DiffEditorTool(BaseTool):
    name = "diffeditortool"
    description = '''
    Performs a precise replacement of a given text snippet in a specified file.
    It takes the following inputs:
    - path: The path to the target file.
    - old_text: The exact substring that should be replaced.
    - new_text: The new substring that replaces the old one.

    The tool will:
    1. Read the file contents.
    2. Search for `old_text` within the file.
    3. If found, replace the first occurrence of `old_text` with `new_text`.
    4. Write the modified content back to the file.
    5. Return a success message if successful, or indicate that the old_text was not found.
    '''

    input_schema = {
        "type": "object",
        "properties": {
            "path": {
                "type": "string",
                "description": "Path to the file to be edited."
            },
            "old_text": {
                "type": "string",
                "description": "Exact substring in the file to replace."
            },
            "new_text": {
                "type": "string",
                "description": "New substring that will replace old_text."
            }
        },
        "required": ["path", "old_text", "new_text"]
    }

    def execute(self, **kwargs) -> str:
        path = kwargs.get("path")
        old_text = kwargs.get("old_text")
        new_text = kwargs.get("new_text")

        # Check if file exists
        if not os.path.isfile(path):
            return f"Error: File does not exist at path: {path}"

        # Read the file content
        try:
            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            return f"Error reading file {path}: {str(e)}"

        # Locate the old_text in the file
        index = content.find(old_text)
        if index == -1:
            return f"'{old_text}' not found in the file. No changes made."

        # Replace the first occurrence of old_text with new_text
        # Since find gave us the exact start, we can do a direct substring replacement:
        new_content = content[:index] + new_text + content[index+len(old_text):]

        # Write the updated content back to the file
        try:
            with open(path, 'w', encoding='utf-8') as f:
                f.write(new_content)
        except Exception as e:
            return f"Error writing updated content to file {path}: {str(e)}"

        return f"Successfully replaced '{old_text}' with '{new_text}' in {path}."



================================================
FILE: tools/duckduckgotool.py
================================================
from tools.base import BaseTool
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote_plus

class DuckduckgoTool(BaseTool):
    name = "duckduckgotool"
    description = '''
    Performs a search using DuckDuckGo and returns the top search results.
    Returns titles, snippets, and URLs of the search results.
    Use this tool when you need to search for current information on the internet.
    '''
    input_schema = {
        "type": "object",
        "properties": {
            "query": {
                "type": "string",
                "description": "The search query to look up"
            },
            "num_results": {
                "type": "integer",
                "description": "Number of results to return (default: 8)", 
                "default": 8
            }
        },
        "required": ["query"]
    }

    def execute(self, **kwargs) -> str:
        query = kwargs.get("query")
        num_results = kwargs.get("num_results", 8)

        url = f"https://html.duckduckgo.com/html/?q={quote_plus(query)}"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }

        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            results = []
            for result in soup.select('.result')[:num_results]:
                title_elem = result.select_one('.result__title')
                snippet_elem = result.select_one('.result__snippet')
                url_elem = result.select_one('.result__url')
                
                if title_elem and snippet_elem:
                    title = title_elem.get_text(strip=True)
                    snippet = snippet_elem.get_text(strip=True)
                    url = url_elem.get('href') if url_elem else None
                    
                    results.append(f"Title: {title}\nSnippet: {snippet}\nURL: {url}\n")

            if not results:
                return "No results found."
                
            return "\n".join(results)

        except requests.RequestException as e:
            return f"Error performing search: {str(e)}"


================================================
FILE: tools/e2bcodetool.py
================================================
from tools.base import BaseTool
from e2b_code_interpreter import Sandbox
from dotenv import load_dotenv
import os
import time
import json
import base64

class E2bCodeTool(BaseTool):
    name = "e2bcodetool"
    description = '''
    Executes Python code in a sandboxed environment using e2b-code-interpreter.
    Features:
    - Execute Python code safely in isolation
    - Upload files to sandbox
    - Download files from sandbox
    - Support for environment variables
    Returns execution results including stdout, stderr, and file contents.
    '''
    input_schema = {
        "type": "object",
        "properties": {
            "code": {
                "type": "string",
                "description": "Python code to execute"
            },
            "env_vars": {
                "type": "object",
                "description": "Dictionary of environment variables",
                "additionalProperties": {"type": "string"}
            },
            "upload_files": {
                "type": "array",
                "description": "List of files to upload to sandbox",
                "items": {
                    "type": "object",
                    "properties": {
                        "local_path": {"type": "string"},
                        "sandbox_path": {"type": "string"},
                        "content": {"type": "string"}
                    },
                    "required": ["sandbox_path", "content"]
                }
            },
            "download_paths": {
                "type": "array",
                "description": "List of file paths to download from sandbox",
                "items": {"type": "string"}
            }
        },
        "required": ["code"]
    }

    def execute(self, **kwargs) -> str:
        try:
            load_dotenv()
            
            code = kwargs.get("code")
            upload_files = kwargs.get("upload_files", [])
            download_paths = kwargs.get("download_paths", [])
            
            # Create sandbox instance
            sandbox = Sandbox()
            
            # Upload files if specified
            uploaded_files = []
            for file_spec in upload_files:
                try:
                    sandbox_path = file_spec["sandbox_path"]
                    content = file_spec["content"]
                    
                    # Handle both text and base64 content
                    if ";base64," in content:
                        # Extract base64 data
                        content = content.split(";base64,")[1]
                        file_content = base64.b64decode(content)
                    else:
                        file_content = content.encode('utf-8')
                        
                    sandbox.files.write(sandbox_path, file_content)
                    uploaded_files.append(sandbox_path)
                except Exception as e:
                    return json.dumps({
                        "success": False,
                        "error": f"Failed to upload file {sandbox_path}: {str(e)}",
                        "stdout": "",
                        "stderr": ""
                    }, indent=2)

            # Execute code
            result = sandbox.run_code(code)
            
            # Download requested files
            downloaded_files = {}
            for file_path in download_paths:
                try:
                    content = sandbox.files.read(file_path)
                    # Convert binary content to base64
                    if isinstance(content, bytes):
                        content = base64.b64encode(content).decode('utf-8')
                        content = f"data:application/octet-stream;base64,{content}"
                    downloaded_files[file_path] = content
                except Exception as e:
                    downloaded_files[file_path] = f"Error downloading: {str(e)}"
            
            response = {
                "stdout": result.logs.stdout,
                "stderr": result.logs.stderr,
                "success": True,
                "error": None,
                "uploaded_files": uploaded_files,
                "downloaded_files": downloaded_files
            }
            
            return json.dumps(response, indent=2)
            
        except Exception as e:
            return json.dumps({
                "success": False,
                "error": f"Tool execution failed: {str(e)}",
                "stdout": "",
                "stderr": "",
                "uploaded_files": [],
                "downloaded_files": {}
            }, indent=2)


================================================
FILE: tools/filecontentreadertool.py
================================================
from tools.base import BaseTool
import os
import json
import mimetypes

class FileContentReaderTool(BaseTool):
    name = "filecontentreadertool"
    description = '''
    Reads content from multiple files and returns their contents.
    Accepts a list of file paths and returns a dictionary with file paths as keys
    and their content as values.
    Handles file reading errors gracefully with built-in Python exceptions.
    When given a directory, recursively reads all text files while skipping binaries and common ignore patterns.
    '''
    
    # Files and directories to ignore
    IGNORE_PATTERNS = {
        # Hidden files and directories
        '.git', '.svn', '.hg', '.DS_Store', '.env', '.idea', '.vscode', '.settings',
        # Build directories
        'node_modules', '__pycache__', 'build', 'dist', 'venv', 'env', 'bin', 'obj',
        'target', 'out', 'Debug', 'Release', 'x64', 'x86', 'builds', 'coverage',
        # Binary file extensions
        '.pyc', '.pyo', '.so', '.dll', '.dylib', '.pdb', '.ilk', '.exp', '.map',
        '.exe', '.bin', '.dat', '.db', '.sqlite', '.sqlite3', '.o', '.cache',
        '.lib', '.a', '.sys', '.ko', '.obj', '.iso', '.msi', '.msp', '.msm',
        '.img', '.dmg', '.class', '.jar', '.war', '.ear', '.aar', '.apk',
        # Media files
        '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.psd', '.ai', '.eps',
        '.mp3', '.mp4', '.avi', '.mov', '.wav', '.aac', '.m4a', '.wma', '.midi',
        '.flv', '.mkv', '.wmv', '.m4v', '.webm', '.3gp', '.mpg', '.mpeg', '.m2v',
        '.ogg', '.ogv', '.webp', '.heic', '.raw', '.svg', '.ico', '.icns',
        # Archive files
        '.zip', '.tar', '.gz', '.rar', '.7z', '.pkg', '.deb', '.rpm', '.snap',
        '.bz2', '.xz', '.cab', '.iso', '.tgz', '.tbz2', '.lz', '.lzma', '.tlz',
        # IDE and editor files
        '.sln', '.suo', '.user', '.workspace', '.project', '.classpath', '.iml',
        # Log and temp files
        '.log', '.tmp', '.temp', '.swp', '.bak', '.old', '.orig', '.pid'
    }

    input_schema = {
        "type": "object",
        "properties": {
            "file_paths": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "List of file paths to read"
            }
        },
        "required": ["file_paths"]
    }

    def _should_skip(self, path: str) -> bool:
        """Determine if a file or directory should be skipped."""
        name = os.path.basename(path)
        ext = os.path.splitext(name)[1].lower()

        # Skip if name or extension matches ignore patterns
        if name in self.IGNORE_PATTERNS or ext in self.IGNORE_PATTERNS:
            return True

        # Skip hidden files/directories (starting with .)
        if name.startswith('.'):
            return True

        # If it's a file, check if it's binary using mimetype
        if os.path.isfile(path):
            mime_type, _ = mimetypes.guess_type(path)
            if mime_type and not mime_type.startswith('text/'):
                return True

        return False

    def _read_file(self, file_path: str) -> str:
        """Safely read a file and handle errors."""
        try:
            if not os.path.exists(file_path):
                return "Error: File not found"

            if self._should_skip(file_path):
                return "Skipped: Binary or ignored file type"

            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read()

        except PermissionError:
            return "Error: Permission denied"
        except IsADirectoryError:
            return "Error: Path is a directory"
        except UnicodeDecodeError:
            return "Error: Unable to decode file (likely binary)"
        except Exception as e:
            return f"Error: {str(e)}"

    def _read_directory(self, dir_path: str) -> dict:
        """Recursively read all files in a directory."""
        results = {}

        try:
            for root, dirs, files in os.walk(dir_path):
                # Filter out directories to skip
                dirs[:] = [d for d in dirs if not self._should_skip(os.path.join(root, d))]

                # Process files
                for file in files:
                    file_path = os.path.join(root, file)
                    if not self._should_skip(file_path):
                        content = self._read_file(file_path)
                        results[file_path] = content

        except Exception as e:
            results[dir_path] = f"Error reading directory: {str(e)}"

        return results

    def execute(self, **kwargs) -> str:
        file_paths = kwargs.get('file_paths', [])
        results = {}

        try:
            for path in file_paths:
                if os.path.isdir(path):
                    # If it's a directory, read it recursively
                    dir_results = self._read_directory(path)
                    results.update(dir_results)
                else:
                    # If it's a file, read it directly
                    content = self._read_file(path)
                    results[path] = content

            return json.dumps(results, indent=2)

        except Exception as e:
            return json.dumps({"error": str(e)}, indent=2)


================================================
FILE: tools/filecreatortool.py
================================================
from tools.base import BaseTool
import os
import json
from typing import Union, List, Dict
from pathlib import Path

class FileCreatorTool(BaseTool):
    name = "filecreatortool"
    description = '''
    Creates new files with specified content.
    
    IMPORTANT: The input must follow this exact structure:
    1. For a single file:
       {
           "files": {
               "path": "path/to/file.txt",
               "content": "file content here"
           }
       }
    
    2. For multiple files:
       {
           "files": [
               {
                   "path": "path/to/file1.txt",
                   "content": "content for file 1"
               },
               {
                   "path": "path/to/file2.txt",
                   "content": "content for file 2"
               }
           ]
       }
    
    Features:
    - Creates parent directories automatically if they don't exist
    - Supports both text and binary content
    - Can create multiple files in one call
    - Handles JSON content automatically
    
    Optional parameters:
    - binary: boolean (default: false) - Set to true for binary files
    - encoding: string (default: "utf-8") - Specify file encoding
    
    Example usage:
    1. Create a Python file:
       {
           "files": {
               "path": "test.py",
               "content": "def hello():\\n    print('Hello, World!')"
           }
       }
    
    2. Create multiple files:
       {
           "files": [
               {
                   "path": "src/main.py",
                   "content": "# Main file content"
               },
               {
                   "path": "src/utils.py",
                   "content": "# Utils file content"
               }
           ]
       }
    '''
    input_schema = {
        "type": "object",
        "properties": {
            "files": {
                "oneOf": [
                    {
                        "type": "object",
                        "properties": {
                            "path": {"type": "string"},
                            "content": {"oneOf": [{"type": "string"}, {"type": "object"}]},
                            "binary": {"type": "boolean", "default": False},
                            "encoding": {"type": "string", "default": "utf-8"}
                        },
                        "required": ["path", "content"]
                    },
                    {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "path": {"type": "string"},
                                "content": {"oneOf": [{"type": "string"}, {"type": "object"}]},
                                "binary": {"type": "boolean", "default": False},
                                "encoding": {"type": "string", "default": "utf-8"}
                            },
                            "required": ["path", "content"]
                        }
                    }
                ]
            }
        },
        "required": ["files"]
    }

    def execute(self, **kwargs) -> str:
        """
        Execute the file creation process.
        
        Args:
            **kwargs: Must contain 'files' key with either a dict or list of dicts
                     Each dict must have 'path' and 'content' keys
        
        Returns:
            str: JSON string containing results of file creation operations
        """
        files = kwargs.get('files', [])
        if isinstance(files, dict):
            files = [files]

        results = []
        for file_spec in files:
            try:
                path = Path(file_spec['path'])
                content = file_spec['content']
                binary = file_spec.get('binary', False)
                encoding = file_spec.get('encoding', 'utf-8')

                # Create parent directories
                path.parent.mkdir(parents=True, exist_ok=True)

                # Handle content
                if isinstance(content, dict):
                    content = json.dumps(content, indent=2)

                # Write file
                mode = 'wb' if binary else 'w'
                if binary:
                    if isinstance(content, str):
                        content = content.encode(encoding)
                    with open(path, mode) as f:
                        f.write(content)
                else:
                    with open(path, mode, encoding=encoding, newline='') as f:
                        f.write(content)

                results.append({
                    'path': str(path),
                    'success': True,
                    'size': path.stat().st_size
                })

            except Exception as e:
                results.append({
                    'path': str(path) if 'path' in locals() else None,
                    'success': False,
                    'error': str(e)
                })

        return json.dumps({
            'created_files': len([r for r in results if r['success']]),
            'failed_files': len([r for r in results if not r['success']]),
            'results': results
        }, indent=2)


================================================
FILE: tools/fileedittool.py
================================================
from tools.base import BaseTool
import os
import re

class FileEditTool(BaseTool):
    name = "fileedittool"
    description = '''
    A tool for editing file contents with support for:
    - Full file content replacement
    - Partial content editing by line numbers
    - Pattern-based text search and replace
    - Multiple file type support
    - Error handling for file operations
    '''
    input_schema = {
        "type": "object",
        "properties": {
            "file_path": {"type": "string", "description": "Path to the file to edit"},
            "edit_type": {"type": "string", "enum": ["full", "partial"], "description": "Type of edit operation"},
            "new_content": {"type": "string", "description": "New content to write"},
            "start_line": {"type": "integer", "description": "Starting line number for partial edits"},
            "end_line": {"type": "integer", "description": "Ending line number for partial edits"},
            "search_pattern": {"type": "string", "description": "Pattern to search for in partial edits"},
            "replacement_text": {"type": "string", "description": "Text to replace matched patterns"}
        },
        "required": ["file_path", "edit_type", "new_content"]
    }

    def execute(self, **kwargs) -> str:
        file_path = kwargs.get('file_path')
        edit_type = kwargs.get('edit_type')
        new_content = kwargs.get('new_content')
        
        try:
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"File not found: {file_path}")

            with open(file_path, 'r', encoding='utf-8') as file:
                original_content = file.read()
                lines = original_content.splitlines()

            if edit_type == "full":
                updated_content = new_content
            else:
                start_line = kwargs.get('start_line')
                end_line = kwargs.get('end_line')
                search_pattern = kwargs.get('search_pattern')
                replacement_text = kwargs.get('replacement_text')

                if start_line is not None and end_line is not None:
                    updated_content = self._edit_by_lines(lines, start_line, end_line, new_content)
                elif search_pattern and replacement_text:
                    updated_content = self._find_and_replace(original_content, search_pattern, replacement_text)
                else:
                    raise ValueError("Invalid partial edit parameters")

            with open(file_path, 'w', encoding='utf-8') as file:
                file.write(updated_content)

            return f"File successfully updated: {file_path}\n{updated_content}"

        except Exception as e:
            return f"Error editing file: {str(e)}"

    def _edit_by_lines(self, lines: list, start_line: int, end_line: int, new_content: str) -> str:
        if start_line < 1 or end_line > len(lines) or start_line > end_line:
            raise ValueError("Invalid line numbers")

        lines[start_line-1:end_line] = new_content.splitlines()
        return '\n'.join(lines)

    def _find_and_replace(self, content: str, pattern: str, replacement: str) -> str:
        try:
            return re.sub(pattern, replacement, content)
        except re.error as e:
            raise ValueError(f"Invalid regular expression pattern: {str(e)}")


================================================
FILE: tools/lintingtool.py
================================================
from tools.base import BaseTool
import subprocess
from typing import List
import json

class LintingTool(BaseTool):
    name = "lintingtool"
    description = '''
    Runs the Ruff linter on the given Python files or directories to detect and fix coding style or syntax issues.
    Supports configurable rule selection, automatic fixes, unsafe fixes, adding noqa directives, and watch mode.
    Returns the linter output as a string.
    '''

    input_schema = {
        "type": "object",
        "properties": {
            "paths": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of file or directory paths to lint. Defaults to current directory if none provided."
            },
            "fix": {
                "type": "boolean",
                "default": False,
                "description": "Whether to automatically fix fixable issues."
            },
            "unsafe_fixes": {
                "type": "boolean",
                "default": False,
                "description": "Enable unsafe fixes."
            },
            "add_noqa": {
                "type": "boolean",
                "default": False,
                "description": "Add noqa directives to all lines with violations."
            },
            "select": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of rule codes to exclusively enforce."
            },
            "extend_select": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of additional rule codes to enforce alongside the default selection."
            },
            "watch": {
                "type": "boolean",
                "default": False,
                "description": "Watch for file changes and re-run linting on change."
            },
            "exit_zero": {
                "type": "boolean",
                "default": False,
                "description": "Exit with code 0 even if violations are found."
            },
            "exit_non_zero_on_fix": {
                "type": "boolean",
                "default": False,
                "description": "Exit with non-zero even if all violations were fixed automatically."
            }
        },
        "required": []
    }

    def execute(self, **kwargs) -> str:
        paths = kwargs.get("paths", [])
        fix = kwargs.get("fix", False)
        unsafe_fixes = kwargs.get("unsafe_fixes", False)
        add_noqa = kwargs.get("add_noqa", False)
        select = kwargs.get("select", [])
        extend_select = kwargs.get("extend_select", [])
        watch = kwargs.get("watch", False)
        exit_zero = kwargs.get("exit_zero", False)
        exit_non_zero_on_fix = kwargs.get("exit_non_zero_on_fix", False)

        cmd = ["uv", "run", "ruff", "check"]

        if fix:
            cmd.append("--fix")
        if unsafe_fixes:
            cmd.append("--unsafe-fixes")
        if add_noqa:
            cmd.append("--add-noqa")
        if watch:
            cmd.append("--watch")
        if exit_zero:
            cmd.append("--exit-zero")
        if exit_non_zero_on_fix:
            cmd.append("--exit-non-zero-on-fix")

        for rule in select:
            cmd.extend(["--select", rule])
        for rule in extend_select:
            cmd.extend(["--extend-select", rule])

        if not paths:
            paths = ["."]
        cmd.extend(paths)

        try:
            result = subprocess.run(
                cmd,
                text=True,
                capture_output=True,
                check=False
            )
            return result.stdout + result.stderr
        except Exception as e:
            return f"Error running ruff check: {str(e)}"



================================================
FILE: tools/screenshottool.py
================================================
from tools.base import BaseTool
from typing import List, Dict, Any, Optional
import base64
import io
import json  # Add this import

try:
    import pyautogui
    from PIL import Image
except ImportError as e:
    # If pyautogui or PIL is missing, you may need to rely on the uvpackagemanager tool
    # or instruct the user to install them. For now, just raise an error.
    raise ImportError("The ScreenshotTool requires 'pyautogui' and 'Pillow' to be installed.")

class ScreenshotTool(BaseTool):
    name = "screenshottool"
    description = '''
    Captures a screenshot of the current screen and returns an image block ready to be sent to Claude.
    Optionally, a specific region of the screen can be captured by providing coordinates.

    Inputs:
    - region (optional): A list of four integers [x, y, width, height] specifying the region of the screen to capture.
      If omitted, captures the entire screen.

    The output is a JSON-formatted string that can be included directly as part of the conversation content:
    [
      {
        "type": "image",
        "source": {
          "type": "base64",
          "media_type": "image/png",
          "data": "<base64-encoded png>"
        }
      }
    ]

    This block can be inserted into the messages array sent to Claude via the Messages API.
    '''
    input_schema = {
        "type": "object",
        "properties": {
            "region": {
                "type": "array",
                "items": {"type": "integer"},
                "description": "Optional region [x, y, width, height] to capture",
                "minItems": 4,
                "maxItems": 4
            }
        },
        "required": []
    }

    def execute(self, **kwargs) -> Any:
        region = kwargs.get("region", None)
        if region is not None and len(region) != 4:
            return "Invalid region specified. Must be a list of four integers: [x, y, width, height]."

        try:
            # Take screenshot (full screen or specified region)
            screenshot: Image.Image = pyautogui.screenshot(region=region)

            # Convert to base64
            with io.BytesIO() as buffer:
                screenshot.save(buffer, format="PNG")
                encoded_data = base64.b64encode(buffer.getvalue()).decode("utf-8")

            # Return the image block as a Python list/dict (not as JSON string)
            return [
                {
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": "image/png",
                        "data": encoded_data,
                    }
                }
            ]

        except Exception as e:
            return f"Error capturing screenshot: {str(e)}"



================================================
FILE: tools/toolcreator.py
================================================
from tools.base import BaseTool
from rich.console import Console
from rich.panel import Panel
from pathlib import Path
import os
from dotenv import load_dotenv
import re
import anthropic

load_dotenv()

class ToolCreatorTool(BaseTool):
    name = "toolcreator"
    description = '''
    Creates a new tool based on a natural language description.
    Use this when you need a new capability that isn't available in current tools.
    The tool will be automatically generated and saved to the tools directory.
    Returns the generated tool code and creation status.
    '''
    input_schema = {
        "type": "object",
        "properties": {
            "description": {
                "type": "string",
                "description": "Natural language description of what the tool should do"
            }
        },
        "required": ["description"]
    }

    def __init__(self):
        self.client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
        self.console = Console()
        self.tools_dir = Path(__file__).parent.parent / "tools"  # Fixed path

    def _sanitize_filename(self, name: str) -> str:
        """Convert tool name to valid Python filename"""
        return name + '.py'  # Keep exact name, just add .py

    def _validate_tool_name(self, name: str) -> bool:
        """Validate tool name matches required pattern"""
        return bool(re.match(r'^[a-zA-Z0-9_-]{1,64}$', name))

    def execute(self, **kwargs) -> str:
        description = kwargs.get("description")

        # Create exact same prompt as the original
        prompt = f"""Create a Python tool class that follows our BaseTool interface. The tool should:

1. {description}

Important:
- The filename MUST EXACTLY match the tool name used in the class
- The name property MUST EXACTLY match the class name in lowercase
- For example, if the class is `WeatherTool`, then:
  - name property must be "weathertool"
  - file must be weathertool.py

Here's the required structure (including imports and format):

```python
from tools.base import BaseTool  # This import must be present
import requests  # Add any other required imports

class ToolName(BaseTool):  # Class name must match name property in uppercase first letter
    name = "toolname"  # Must match class name in lowercase
    description = '''
    Detailed description here.
    Multiple lines for clarity.
    '''
    input_schema = {{
        "type": "object",
        "properties": {{
            # Required input parameters
        }},
        "required": []  # List required parameters
    }}

    def execute(self, **kwargs) -> str:
        # Implementation here
        pass
```

Generate the complete tool implementation following this exact structure.
Return ONLY the Python code without any explanation or markdown formatting.
"""

        try:
            # Get tool implementation from Claude with animation
            response = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=4000,
                temperature=0,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )

            tool_code = response.content[0].text.strip()

            # Extract tool name from the generated code
            name_match = re.search(r'name\s*=\s*["\']([a-zA-Z0-9_-]+)["\']', tool_code)
            if not name_match:
                return "Error: Could not extract tool name from generated code"

            tool_name = name_match.group(1)
            filename = self._sanitize_filename(tool_name)

            # Ensure the tools directory exists
            self.tools_dir.mkdir(exist_ok=True)

            # Save tool to file
            file_path = self.tools_dir / filename
            with open(file_path, 'w') as f:
                f.write(tool_code)

            # Format the response using Panel like the original
            result = f"""[bold green]âœ… Tool created successfully![/bold green]
Tool name: [cyan]{tool_name}[/cyan]
File created: [cyan]{filename}[/cyan]

[bold]Generated Tool Code:[/bold]
{Panel(tool_code, border_style="green")}

[bold green]âœ¨ Tool is ready to use![/bold green]
Type 'refresh' to load your new tool."""

            return result

        except Exception as e:
            return f"[bold red]Error creating tool:[/bold red] {str(e)}"



================================================
FILE: tools/uvpackagemanager.py
================================================
import logging
import subprocess
from typing import List, Optional

from tools.base import BaseTool


class UVPackageManager(BaseTool):
    name = "uvpackagemanager"
    description = '''
    Comprehensive interface to the uv package manager providing package management,
    project management, Python version management, tool management, and script support.
    Supports all major platforms with pip compatibility.
    '''
    input_schema = {
        "type": "object",
        "properties": {
            "command": {
                "type": "string",
                "description": "Primary command (install, remove, update, init, venv, etc.)"
            },
            "packages": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of packages to operate on"
            },
            "python_version": {
                "type": "string",
                "description": "Python version for operations that require it"
            },
            "project_path": {
                "type": "string",
                "description": "Path to project directory"
            },
            "requirements_file": {
                "type": "string",
                "description": "Path to requirements file"
            },
            "global_install": {
                "type": "boolean",
                "description": "Whether to install packages globally"
            }
        },
        "required": ["command"]
    }

    def execute(self, **kwargs) -> str:
        command = kwargs.get("command")
        packages = kwargs.get("packages", [])
        python_version = kwargs.get("python_version")
        project_path = kwargs.get("project_path", ".")
        requirements_file = kwargs.get("requirements_file")
        global_install = kwargs.get("global_install", False)

        try:
            if command == "install":
                return self._install_packages(packages, requirements_file, global_install)
            elif command == "remove":
                return self._remove_packages(packages)
            elif command == "update":
                return self._update_packages(packages)
            elif command == "list":
                return self._list_packages()
            elif command == "init":
                return self._init_project(project_path)
            elif command == "venv":
                return self._create_venv(project_path, python_version)
            elif command == "python":
                return self._manage_python(python_version)
            elif command == "compile":
                return self._compile_requirements()
            elif command == "run":
                return self._run_script(kwargs.get("script"), packages)
            else:
                return f"Unknown command: {command}"
        except Exception as e:
            logging.error(f"Error executing UV command: {e!s}")
            return f"Error: {e!s}"

    def _run_uv_command(self, args: List[str]) -> str:
        try:
            result = subprocess.run(
                ["uv"] + args,
                capture_output=True,
                text=True,
                check=True
            )
            return result.stdout
        except subprocess.CalledProcessError as e:
            raise Exception(f"UV command failed: {e.stderr}")

    def _install_packages(self, packages: List[str], requirements_file: Optional[str], global_install: bool) -> str:
        args = ["pip", "install"]
        if global_install:
            args.append("--global")
        if requirements_file:
            args.extend(["-r", requirements_file])
        if packages:
            args.extend(packages)
        return self._run_uv_command(args)

    def _remove_packages(self, packages: List[str]) -> str:
        return self._run_uv_command(["pip", "uninstall", "-y"] + packages)

    def _update_packages(self, packages: List[str]) -> str:
        args = ["pip", "install", "--upgrade"]
        if packages:
            args.extend(packages)
        return self._run_uv_command(args)

    def _list_packages(self) -> str:
        return self._run_uv_command(["pip", "list"])

    def _init_project(self, project_path: str) -> str:
        return self._run_uv_command(["init", project_path])

    def _create_venv(self, path: str, python_version: Optional[str]) -> str:
        args = ["venv"]
        if python_version:
            args.extend(["--python", python_version])
        args.append(path)
        return self._run_uv_command(args)

    def _manage_python(self, version: Optional[str]) -> str:
        if not version:
            return self._run_uv_command(["python", "list"])
        return self._run_uv_command(["python", "install", version])

    def _compile_requirements(self) -> str:
        return self._run_uv_command(["pip", "compile", "requirements.in"])

    def _run_script(self, script: str, packages: List[str]) -> str:
        args = ["run"]
        if packages:
            args.extend(["--with"] + packages)
        args.extend(["--", "python", script])
        return self._run_uv_command(args)


================================================
FILE: tools/webscrapertool.py
================================================
from tools.base import BaseTool
import requests
from bs4 import BeautifulSoup, Comment
import re

class WebScraperTool(BaseTool):
    name = "webscrapertool"
    description = '''
    An enhanced web scraper that fetches a web page, extracts and returns its main textual content,
    along with the page title and meta description if available. It attempts to identify the main
    article content more intelligently, remove navigational and advertising elements, and preserve
    heading structure for context. Useful for obtaining cleaner, more relevant textual information.
    '''

    input_schema = {
        "type": "object",
        "properties": {
            "url": {
                "type": "string",
                "description": "The URL of the webpage to scrape"
            }
        },
        "required": ["url"]
    }

    def execute(self, **kwargs) -> str:
        url = kwargs.get("url")

        try:
            headers = {
                'User-Agent': ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                               'AppleWebKit/537.36 (KHTML, like Gecko) '
                               'Chrome/91.0.4472.124 Safari/537.36')
            }
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')

            # Remove script, style, and other irrelevant elements
            for elem in soup(["script", "style", "noscript", "iframe", "svg", "canvas", "object"]):
                elem.decompose()

            # Remove comments
            for comment in soup.find_all(text=lambda text: isinstance(text, Comment)):
                comment.extract()

            # Identify main content container
            main_container = (
                soup.find('main') or
                soup.find('article') or
                soup.find(attrs={'id': re.compile(r'(main|content|article)', re.I)}) or
                soup.find(attrs={'class': re.compile(r'(main|content|article)', re.I)})
            )

            # If no main-like container found, fallback to body or entire doc
            if not main_container:
                main_container = soup.find('body')
            if not main_container:
                main_container = soup

            # Remove elements likely not part of main content
            # including nav, footer, aside, forms, and common ad-based sections
            for tag_name in ["nav", "footer", "aside", "form", "header"]:
                for elem in main_container.find_all(tag_name):
                    elem.decompose()

            # Remove known ad or irrelevant containers by class or id hints
            # E.g., "sidebar", "ad", "advertisement"
            for elem in main_container.find_all(attrs={'class': re.compile(r'(sidebar|nav|menu|ad|advert)', re.I)}):
                elem.decompose()
            for elem in main_container.find_all(attrs={'id': re.compile(r'(sidebar|nav|menu|ad|advert)', re.I)}):
                elem.decompose()

            # Remove empty elements that are not headings or block-level content
            for elem in main_container.find_all(lambda e: (e.name not in ['h1','h2','h3','h4','h5','h6','p','div','ul','ol','li','section','article','main'] and not e.get_text(strip=True))):
                elem.decompose()

            # Extract page title
            title_elem = soup.find('title')
            page_title = title_elem.get_text(strip=True) if title_elem else ''

            # Extract meta description
            meta_desc = ''
            desc_tag = soup.find('meta', attrs={"name": "description"})
            if desc_tag and desc_tag.get('content'):
                meta_desc = desc_tag['content'].strip()

            # Convert main content to text
            # We'll use get_text with a separator to maintain some structure
            # but we need to carefully handle headings.
            # Let's extract text in a structured way:
            # We'll join block-level elements with newlines, and strip excess whitespace.
            block_elements = ['p','h1','h2','h3','h4','h5','h6','li','section','article','main','div']
            text_chunks = []
            for elem in main_container.find_all(block_elements):
                # Get the text, strip whitespace
                block_text = elem.get_text(" ", strip=True)
                if block_text:
                    text_chunks.append(block_text)

            cleaned_text = "\n\n".join(text_chunks)

            if not cleaned_text.strip():
                # If no text found, return a default message
                return "No readable content found on the webpage."

            # Construct final output
            output_parts = []
            if page_title:
                output_parts.append(f"Title: {page_title}")
            if meta_desc:
                output_parts.append(f"Description: {meta_desc}")
            output_parts.append("Content:")
            output_parts.append(cleaned_text)

            final_output = "\n\n".join(output_parts)

            return final_output

        except requests.RequestException as e:
            return f"Error scraping the webpage: {str(e)}"
        except Exception as e:
            return f"An unexpected error occurred: {str(e)}"


